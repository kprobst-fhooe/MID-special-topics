# Special Topics in Multimodal Interaction

A collection of essential papers and books on diverse topics in Human-Computer Interaction (HCI), specifically in the scope of multimodal interaction. Papers are mainly taken from representative conferences the field of Human-Computer Interaction, such as:

- International Conference on Human Factors in Computing Systems (CHI)
- International Conference on Human-Computer Interaction with Mobile Devices and Services (MobileHCI)
- International Symposium on User Interface Software and Technology (UIST)
- International Conference on Interactive Surfaces and Spaces (ISS)
- International Conference on Tangible, Embedded, and Embodied Interaction (TEI) 
- International Conference on Designing Interactive Systems (DIS)
- International Conference on Human-Computer Interaction (INTERACT)
- International Conference on Mobile and Ubiquitous Multimedia (MUM)
- International Conference on Interactive Media Experiences (IMX)
- International Conference On Computer-Supported Cooperative Work And Social Computing (CSCW)

**Special Topics included:**

- üëã [Gestural Interaction](#-gestural-interaction)
- üß± [Tangible Interaction](#-tangible-interaction)
- üí¨ [Voice Interaction](#-voice-interaction)
- üëÅÔ∏è [Gaze Interaction](#%EF%B8%8F-gaze-interaction)
- üìè [Proxemic & Spatially-Aware Interaction](#-proxemic--spatially-aware-interaction)


<br/>


## ‚ú® Multimodal Interaction


- Oviatt, 1999. Ten Myths of Multimodal Interaction. In Communications of the ACM 42, 11, pp. 74‚Äì81, DOI: [10.1145/319382.319398](https://doi.org/10.1145/319382.319398)

- Oviatt, 2003. Advances in Robust Multimodal Interface Design. In IEEE Computer Graphics and Applications 23, DOI: [10.1109/MCG.2003.1231179](https://doi.org/10.1109/MCG.2003.1231179)

- Reeves, Lai, Larson, Oviatt, Balaji, Buisine, Collings, Cohen, Kraal, Martin, McTear, Raman, Stanney, Su, Wang, 2004. Guidelines for Multimodal User Interface Design. In Communications of the ACM 47, 1, pp. 57‚Äì59, DOI: [10.1145/962081.962106](https://doi.org/10.1145/962081.962106)

- Benford, Schn√§delbach, Koleva, Anastasi, Greenhalgh, Rodden, Green, Ghali, Pridmore, Gaver, Boucher, Walker, Pennington, Schmidt, Gellersen, Steed, 2005. Expected, Sensed, and Desired: A Framework for Designing Sensing-Based Interaction. In ACM Transactions on Computer-Human Interaction 12, 1, pp. 3‚Äì30, DOI: [10.1145/1057237.1057239](https://doi.org/10.1145/1057237.1057239)

- Klemmer, Hartmann, Takayama, 2006. How Bodies Matter: Five Themes for Interaction Design. In Proceedings of the 6th Conference on Designing Interactive Systems (DIS ‚Äò06), pp. 140‚Äì149, DOI: [10.1145/1142405.1142429](https://doi.org/10.1145/1142405.1142429)

- Tzovaras 2008. Multimodal User Interfaces ‚Äì From Signals to Interaction. Springer 

- Dumas, Lalanne, Oviatt, 2009. Multimodal Interfaces: A Survey of Principles, Models and Frameworks. In: Human Machine Interaction. Lecture Notes in Computer Science, vol. 5440. DOI: [810.1007/978-3-642-00437-7_1](https://doi.org/10.1007/978-3-642-00437-7_1)

- Shaked, Winter, 2016. Design of Multimodal Mobile Interfaces. DOI: [10.1515/9781501502736](https://doi.org/10.1515/9781501502736)

- Oviatt, Schuller, Cohen, Sonntag, Potamianos, Kr√ºger, 2017. The Handbook of Multimodal-Multisensor Interfaces: Foundations, User Modeling, and Common Modality Combinations - Volume 1. DOI: [10.1145/3015783](https://doi.org/10.1145/3015783)

- Cheryl Platz, 2020. Design Beyond Devices: Creating Multimodal, Cross-Device Experiences. Rosenfeld Media 


<br/>





## üí¨ Voice Interaction


### General

- Cohen, 2004. Voice User Interface Design, Addison-Wesley [üìñ](voice/2004-Cohen%20-%20Voice%20User%20Interface%20Design.pdf)

- Klein, 2016. Designing for Voice Interfaces, O‚ÄôReilly Media [üìñ](voice/2016-Klein%20Designing%20for%20Voice%20Interfaces.pdf)

- Pearl, 2016. Designing Voice User Interfaces, O‚ÄôReilly Media [üìñ](voice/2016-Pearl%20-%20Designing%20Voice%20User%20Interfaces.pdf)

- Moore, 2017. Is Spoken Language All-or-Nothing? Implications for Future Speech-Based Human-Machine Interaction. In Dialogues with Social Robots. Lecture Notes in Electrical Engineering, vol 427, DOI: [10.1007/978-981-10-2585-3_22 ](https://doi.org/10.1007/978-981-10-2585-3_22)

- Murad, Munteanu, Clark, Cowan, 2018. Design guidelines for hands-free speech interaction. In Proceedings of the 20th International Conference on Human-Computer Interaction with Mobile Devices and Services (MobileHCI ‚Äò18), pp. 269‚Äì276, DOI: [10.1145/3236112.3236149](https://doi.org/10.1145/3236112.3236149)

- **Wei & Landay, 2018. Evaluating Speech-Based Smart Devices Using New Usability Heuristics. In¬†IEEE Pervasive Computing, vol. 17, no. 2, pp. 84-96, DOI: [10.1109/MPRV.2018.022511249](https://doi.10.1109/MPRV.2018.022511249) [üìÑ](voice/2018-Wei%20et%20al.%20-%20Evaluating%20Speech-Based%20Smart%20Devices%20Using%20New%20Usability%20Heuristics.pdf)**

- **Moore & Arar, 2019. Conversational UX Design ‚Äì A Practitioner‚Äôs Guide to the Natural Conversation Framework (Chapter 1)** [üìñ](voice/2019-Moore%20et%20al.%20-%20Conversational%20UX%20Design.pdf)

- Murad, Munteanu, 2019. "I don't know what you're talking about, HALexa": the Case For Voice User Interface Guidelines. In Proceedings of the 1st International Conference on Conversational User Interfaces (CUI '19), Article 9, DOI: [10.1145/3342775.3342795](https://doi.org/10.1145/3342775.3342795)

- Bouzid, Ma, 2022. The Elements of Voice First Style: A Practical Guide to Voice User Interface Design, O'Reilly Media [üìñ](voice/2022-Bouzid%20-%20The%20Elements%20of%20Voice%20First%20Style.pdf)

- **Murad, Candello, Munteanu, 2024. What‚Äôs The Talk on VUI Guidelines? A Meta-Analysis of Guidelines for Voice User Interface Design. In Proceedings of the 5th International Conference on Conversational User Interfac (CUI '23), Article 19, DOI: [10.1145/3571884.3597129](https://doi.org/10.1145/3571884.3597129)**



### Applications


- Oviatt, Cohen, Wu, Vergo, Duncan, Suhm, Bers, Holzman, Winograd, Landay, Larson, Ferro, 2000. Designing the user interface for multimodal speech and pen-based gesture applications: state-of-the-art systems and future research directions. In Hum.-Comput. Interact. 15, 4 (December 2000), pp. 263‚Äì322, DOI: [10.1207/S15327051HCI1504_1](https//doi.org/10.1207/S15327051HCI1504_1)

- Igarashi & Hughes, 2001. Voice as sound: using non-verbal voice input for interactive control. In Proceedings of the 14th annual ACM symposium on User interface software and technology (UIST ‚Äò01), pp. 155‚Äì156, DOI: [10.1145/502348.502372](https//doi.org/10.1145/502348.502372)

- Krum, Omoteso, Ribarsky, Starner, Hodges, 2002. Speech and gesture multimodal control of a whole Earth 3D visualization environment. In Proceedings of the symposium on Data Visualisation 2002 (VISSYM '02), pp. 195‚Äì200

- Kopp, Gesellensetter, Kr√§mer, Wachsmuth, 2005. A conversational agent as museum guide: design and evaluation of a real-world application. In Lecture Notes in Computer Science, pp. 329‚Äì343, DOI: [10.1007/11550617_28](https//doi.org/10.1007/11550617_28)

- Tse, Shen, Greenberg, Forlines, 2006. Enabling interaction with single user applications through speech and gestures on a multi-user tabletop. In Proceedings of the working conference on Advanced visual interfaces (AVI ‚Äò06), pp. 336‚Äì343, DOI: [10.1145/1133265.1133336](https://doi.org/10.1145/1133265.1133336)

- Harada, Saponas, Landay, 2007. VoicePen: augmenting pen input with simultaneous non-linguisitic vocalization. In Proceedings of the 9th international conference on Multimodal interfaces (ICMI ‚Äò07), pp. 178‚Äì185, DOI: [10.1145/1322192.1322225](https://doi.org/10.1145/1322192.1322225)

- Sherwani, Yu, Paek, Czerwinski, Ju, Acero, 2007. Voicepedia: towards speech-based access to unstructured information.¬†In Interspeech.

- Harada, Wobbrock, Landay, 2011. Voice Games: Investigation Into the Use of Non-speech Voice Input for Making Computer Games More Accessible. In Human-Computer Interaction ‚Äì INTERACT 2011, vol 6946, DOI: [10.1007/978-3-642-23774-4_4](https://doi.org/10.1007/978-3-642-23774-4_4)

- Pfeifer Vardoulakis, Ring, Barry, Sidner, Bickmore, 2012. Designing relational agents as long term social companions for older adults. In Proceedings of the 12th international conference on Intelligent Virtual Agents (IVA‚Äô12), pp. 289‚Äì302, DOI: [10.1007/978-3-642-33197-8_30] 

- Portet, Vacher, Golanski, Meillon, 2013.¬†Design and evaluation of a smart home voice interface for the elderly: acceptability and objection aspects. In¬†Pers Ubiquit Comput¬†17,¬†pp. 127‚Äì144, DOI: [10.1007/s00779-011-0470-5]

- Sakamoto, Komatsu, Igarashi, 2013. Voice augmented manipulation: using paralinguistic information to manipulate mobile devices. In Proceedings of the 15th international conference on Human-computer interaction with mobile devices and services (MobileHCI ‚Äò13), pp. 69‚Äì78, DOI: [10.1145/2493190.2493244](https://doi.org/10.1145/2493190.2493244)

- DeVault, Artstein, Benn, Dey, Fast, Gainer, Georgila, Gratch, Hartholt, Lhommet, Lucas, Marsella, Morbini, Nazarian, Scherer, Stratou, Suri, Traum, Wood, Xu, Rizzo, Morency, 2014. SimSensei Kiosk: A Virtual Human Interviewer for Healthcare Decision Support. In Proceedings of the 2014 international conference on Autonomous agents and multi-agent systems (AAMAS ‚Äò14), pp. 1061‚Äì1068

- Braun, Broy, Pfleging, Alt, 2017. A design space for conversational in-vehicle information systems. In Proceedings of the 19th International Conference on Human-Computer Interaction with Mobile Devices and Services (MobileHCI ‚Äò17), Article 79, DOI:[10.1145/3098279.3122122](https://doi.org/10.1145/3098279.3122122)

- Lin, Hsu, Talamonti, Zhang, Oney, Mars, Tang, 2018. Adasa: A Conversational In-Vehicle Digital Assistant for Advanced Driver Assistance Features. In Proceedings of the 31st Annual ACM Symposium on User Interface Software and Technology (UIST ‚Äò18), pp. 531‚Äì542, DOI: [10.1145/3242587.3242593](https://doi.org/10.1145/3242587.3242593)

- Roider, Reisig, Gross, 2018. Just Look: The Benefits of Gaze-Activated Voice Input in the Car. In Adjunct Proceedings of the 10th International Conference on Automotive User Interfaces and Interactive Vehicular Applications (AutomotiveUI ‚Äò18), pp. 210‚Äì214, DOI: [10.1145/3239092.3265968](https://doi.org/10.1145/3239092.3265968)

- Detjen, Faltaous, Geisler, Schneegass, 2019. User-Defined Voice and Mid-Air Gesture Commands for Maneuver-based Interventions in Automated Vehicles. In Proceedings of Mensch und Computer 2019 (MuC‚Äô19), pp. 341‚Äì348, DOI: [10.1145/3340764.3340798](https://doi.org/10.1145/3340764.3340798)

- Fernandes, Abreu, Almeida, Santos, 2019. A Review of Voice User Interfaces for Interactive TV. In: Applications and Usability of Interactive TV. jAUTI 2018. Communications in Computer and Information Science, vol 1004, DOI: [10.1007/978-3-030-23862-9_9](https://doi.org/10.1007/978-3-030-23862-9_9)

- **Mayer, Laput, Harrison, 2020. Enhancing Mobile Voice Assistants with WorldGaze. In Proceedings of the 38th Annual SIGCHI Conference on Human Factors in Computing Systems (CHI ‚Äò20), DOI: [10.1145/3313831.3376479](https://doi.org/10.1145/3313831.3376479)**

- Williams, Cambre, Bicking, Wallin, Tsai, Kaye, 2020. Toward Voice-Assisted Browsers: A Preliminary Study with Firefox Voice. In Proceedings of the 2nd Conference on Conversational User Interfaces (CUI ‚Äò20), Article 49, DOI: [10.1145/3405755.3406154](https://doi.org/10.1145/3405755.3406154)

- Hermann, Pl√ºckthun, Dogang√ºn, Hesenius, 2022. User-Defined Gesture and Voice Control in Human-Drone Interaction for Police Operations. In Proceedings of the Nordic Human-Computer Interaction Conference (NordiCHI '22), DOI: [10.1145/3546155.3546661](https://doi.org/10.1145/3546155.3546661)

- Khan, Newn, Bailey, Velloso, 2022. Integrating Gaze and Speech for Enabling Implicit Interactions. In Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems (CHI '22). DOI: [10.1145/3491102.3502134](https://doi.org/10.1145/3491102.3502134) [üìÑ](gaze/2022-Khan%20-%20Integrating%20Gaze%20and%20Speech.pdf)

- Parthiban, Maes, Sellier, Sluyters, Vanderdonckt, 2022. Gestural-Vocal Coordinated Interaction on Large Displays. In Companion of the 2022 ACM SIGCHI Symposium on Engineering Interactive Computing Systems (EICS '22), pp. 26-32, DOI: [10.1145/3531706.3536457](https://doi.org/10.1145/3531706.3536457)

<br/>



## üëÅÔ∏è Gaze Interaction


### General

- **Jacob, 1990. What you look at is what you get: eye movement-based interaction techniques. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI ‚Äò90), pp. 11‚Äì18, DOI: [10.1145/97243.97246](https://doi.org/10.1145/97243.97246)**

- Sibert & Jacob, 2000. Evaluation of eye gaze interaction. In Proceedings of the SIGCHI conference on Human Factors in Computing Systems (CHI ‚Äò00), pp. 281‚Äì288, DOI: [10.1145/332040.332445](https://doi.org/10.1145/332040.332445)

- Kumar, 2007. Gaze-Enhanced User Interface Design. Phd Thesis, Stanford University [üéì](gaze/2007-Kumar%20-%20Gaze-Enhanced%20User%20Interface%20Design.pdf)

- Vertegaal, 2008. A Fitts Law comparison of eye tracking and manual input in the selection of visual targets. In Proceedings of the 10th international conference on Multimodal interfaces (ICMI '08), pp. 241‚Äì248, DOI: [10.1145/1452392.1452443](https://doi.org/10.1145/1452392.1452443) 

- Vrzakova & Bednarik, 2013. That's not Norma(n/l): A Detailed Analysis of Midas Touch in Gaze-based Problem-Solving. In CHI '13 Extended Abstracts on Human Factors in Computing Systems (CHI EA ‚Äò13), pp. 85‚Äì90, DOI: [10.1145/2468356.2468373](https://doi.org/10.1145/2468356.2468373)

- Majaranta & Bulling. 2014. Eye Tracking and Eye-Based Human‚ÄìComputer Interaction. In Advances in Physiological Computing, Chapter 3, pp. 39‚Äì65, DOI: [10.1007/978-1-4471-6392-3_3](http://dx.doi.org/10.1007/978-1-4471-6392-3_3)

- Feit, Williams, Toledo, Paradiso, Kulkarni, Kane, Ringel Morris, 2017. Toward Everyday Gaze Input: Accuracy and Precision of Eye Tracking and Implications for Design. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (CHI ‚Äò17), pp. 1118‚Äì1130, DOI: [10.1145/3025453.3025599](https://doi.org/10.1145/3025453.3025599) 

- Klaib, Alsrehin, Melhem, Bashtawi, Magableh, 2020. Eye Tracking Algorithms, Techniques, Tools, and Applications with an Emphasis on Machine Learning and Internet of Things Technologies (Chapter 7), DOI: [10.1016/j.eswa.2020.114037](https://doi.org/10.1016/j.eswa.2020.114037) [üìÑ](gaze/2020-K%7E1.PDF)


### Applications


- Smith & Graham, 2006. Use of eye movements for video game control. In Proceedings of the 2006 ACM SIGCHI international conference on Advances in computer entertainment technology (ACE ‚Äò06), DOI: [10.1145/1178823.1178847](https://doi.org/10.1145/1178823.1178847) 

- Tall, Alapetite, San Agustin, Skovsgaard, Hansen, Witzner Hansen, M√∏llenbach, 2009. Gaze-controlled driving. In CHI '09 Extended Abstracts on Human Factors in Computing Systems (CHI EA ‚Äò09), pp. 4387‚Äì4392, DOI: [10.1145/1520340.1520671](https://doi.org/10.1145/1520340.1520671) 

- Turner, Bulling, Gellersen, 2011. Combining gaze with manual interaction to extend physical reach. In Proceedings of the 1st international workshop on pervasive eye tracking & mobile eye-based interaction (PETMEI ‚Äò11), pp. 33‚Äì36, DOI: [10.1145/2029956.2029966](https://doi.org/10.1145/2029956.2029966) 

- Stellmach & Dachselt, 2012. Designing gaze-based user interfaces for steering in virtual environments. In Proceedings of the Symposium on Eye Tracking Research and Applications (ETRA ‚Äò12), pp. 131‚Äì138, DOI: [10.1145/2168556.216857](https://doi.org/10.1145/2168556.216857) 

- Stellmach & Dachselt, 2012. Look & touch: gaze-supported target acquisition. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI ‚Äò12), pp. 2981‚Äì2990, DOI: [10.1145/2207676.2208709](https://doi.org/10.1145/2207676.2208709)

- G√∂bel, Klamka, Siegel, Vogt, Stellmach, Dachselt, 2013. Gaze-Supported Foot Interaction in Zoomable Information Spaces. In: Extended Abstracts on Human Factors in Computing Systems, pp. 3059‚Äì3062, DOI: [10.1145/2468356.2479610](https://doi.org/10.1145/2468356.2479610) 

- Pfeuffer, Alexander, Chong, Gellersen, 2014. Gaze-touch: combining gaze with multi-touch for interaction on the same surface. In Proceedings of the 27th annual ACM symposium on User interface software and technology (UIST ‚Äò14), 509‚Äì518, DOI: [10.1145/2642918.2647397](https://doi.org/10.1145/2642918.2647397) 

- Pfeuffer, Alexander, Chong, Zhang, Gellersen. 2015, Gaze-Shifting: Direct-Indirect Input with Pen and Touch Modulated by Gaze. In Proceedings of the 28th Annual ACM Symposium on User Interface Software & Technology (UIST ‚Äò15), pp. 373‚Äì383, DOI: [10.1145/2807442.2807460](https://doi.org/10.1145/2807442.2807460)

- Hansen, Lund, Biermann, M√∏llenbach, Sztuk, San Agustin, 2016. Wrist-worn pervasive gaze interaction. In Proceedings of the Ninth Biennial ACM Symposium on Eye Tracking Research &amp; Applications (ETRA ‚Äò16), pp. 57‚Äì64, DOI: [10.1145/2857491.2857514](https://doi.org/10.1145/2857491.2857514)

- D'Angelo & Gergle, 2016. Gazed and Confused: Understanding and Designing Shared Gaze for Remote Collaboration. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems (CHI ‚Äò16), pp. 2492‚Äì2496, DOI: [10.1145/2858036.2858499](https://doi.org/10.1145/2858036.2858499)

- Pfeuffer & Gellersen, 2016. Gaze and Touch Interaction on Tablets. In Proceedings of the 29th Annual Symposium on User Interface Software and Technology (UIST ‚Äò16), pp. 301‚Äì311, DOI: [10.1145/2984511.2984514](https://doi.org/10.1145/2984511.2984514)

- D'Angelo & Begel, 2017. Improving Communication Between Pair Programmers Using Shared Gaze Awareness. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (CHI ‚Äò17), pp. 6245‚Äì6290, DOI: [10.1145/3025453.3025573](https://doi.org/10.1145/3025453.3025573)

- Khamis, Hoesl, Klimczak, Reiss, Alt, Bulling, 2017. EyeScout: Active Eye Tracking for Position and Movement Independent Gaze Interaction with Large Public Displays. In Proceedings of the 30th Annual ACM Symposium on User Interface Software and Technology (UIST ‚Äò17), pp. 155‚Äì166, DOI: [10.1145/3126594.3126630](https://doi.org/10.1145/3126594.3126630)

- Newn, Allison, Velloso, Vetere. 2018, Looks Can Be Deceiving: Using Gaze Visualisation to Predict and Mislead Opponents in Strategic Gameplay. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI ‚Äò18), DOI: [10.1145/3173574.3173835](https://doi.org/10.1145/3173574.3173835)

- Kyt√∂, Ens, Piumsomboon, Lee, Billinghurst, 2018. Pinpointing: Precise Head- and Eye-Based Target Selection for Augmented Reality. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems, Paper 81, DOI: [10.1145/3173574.3173655](https://doi.org/10.1145/3173574.3173655) 

- Khamis, Kienle, Alt, Bulling, 2018. GazeDrone: Mobile Eye-Based Interaction in Public Space Without Augmenting the User. In Proceedings of the 4th ACM Workshop on Micro Aerial Vehicle Networks, Systems, and Applications (DroNet‚Äô18), pp. 66‚Äì71, DOI: [10.1145/3213526.3213539](https://doi.org/10.1145/3213526.3213539) 

- Khamis, Alt, Bulling, 2018. The Past, Present, and Future of Gaze-Enabled Handheld Mobile Devices: Survey and Lessons Learned. In Proceedings of the 20th International Conference on Human-Computer Interaction with Mobile Devices and Services (MobileHCI ‚Äò18), Article 38, DOI: [10.1145/3229434.3229452](https://doi.org/10.1145/3229434.3229452) 

- Roider, Reisig, Gross, 2018. Just Look: The Benefits of Gaze-Activated Voice Input in the Car. In Adjunct Proceedings of the 10th International Conference on Automotive User Interfaces and Interactive Vehicular Applications (AutomotiveUI ‚Äò18), pp. 210‚Äì214, DOI: [10.1145/3239092.3265968](https://doi.org/10.1145/3239092.3265968) 

- Kim, Choi, Jeong, 2019. Watch & Do: A Smart IoT Interaction System with Object Detection and Gaze Estimation. In IEEE Trans. on Consum. Electron. 65, 2 (May 2019), 195‚Äì204, DOI: [10.1109/TCE.2019.2897758](https://doi.org/10.1109/TCE.2019.2897758) 

- K√ºtt, Lee, Hardacre, Papoutsaki, 2019. Eye-Write: Gaze Sharing for Collaborative Writing. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems (CHI ‚Äò19), Paper 497, DOI: [10.1145/3290605.3300727](https://doi.org/10.1145/3290605.3300727) 

- Newn, Singh , Allison, Madumal, Velloso, Vetere, 2019. Designing Interactions with Intention-Aware Gaze-Enabled Artificial Agents. In: Proceedings INTERACT 2019, DOI: [10.1007/978-3-030-29384-0_17](https://doi.org/10.1007/978-3-030-29384-0_17) 

- Mayer, Laput, Harrison, 2020. Enhancing Mobile Voice Assistants with WorldGaze. In Proceedings of the 38th Annual SIGCHI Conference on Human Factors in Computing Systems (CHI ‚Äò20), DOI: [10.1145/3313831.3376479](https://doi.org/10.1145/3313831.3376479) 

- Pfeuffer, Alexander, Gellersen, 2021. Multi-user Gaze-Based Interaction Techniques on Collaborative Touchscreens. In 2021 Symposium on Eye Tracking Research and Applications (ETRA '21), DOI: [10.1145/3448018.3458016](https://doi.org/10.1145/3448018.3458016) 

- Khan, Newn, Bailey, Velloso, 2022. Integrating Gaze and Speech for Enabling Implicit Interactions. In Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems (CHI '22). DOI: [10.1145/3491102.3502134](https://doi.org/10.1145/3491102.3502134) 

- Reiter, Pfeuffer, Esteves, Mittermeier, Alt, 2022. Look & Turn: One-handed and Expressive Menu Interaction by Gaze and Arm Turns in VR. In 2022 Symposium on Eye Tracking Research and Applications (ETRA '22), DOI: [10.1145/3517031.3529233](https://doi.org/10.1145/3517031.3529233)

- Lystb√¶k, Rosenberg, Pfeuffer, Gr√∏nb√¶k, Gellersen, 2022. Gaze-Hand Alignment: Combining Eye Gaze and Mid-Air Pointing for Interacting with Menus in Augmented Reality. In Proceedings of the ACM on Human-Computer Interaction, DOI: [10.1145/3530886](https://doi.org/10.1145/3530886)

- Cui, Liu, Li, Wang, Zhao, Rashidian, Baik, Ramakrishnan, Wang, Bi, 2023. GlanceWriter: Writing Text by Glancing Over Letters with Gaze. In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems (CHI '23), DOI: [10.1145/3544548.3581269](https://doi.org/10.1145/3544548.3581269)

- Namnakani, Abdrabou, Grizou, Esteves, Khamis, 2023. Comparing Dwell Time, Pursuits and Gaze Gestures for Gaze Interaction on Handheld Mobile Devices. In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems (CHI '23), DOI: [10.1145/3544548.3580871](https://doi.org/10.1145/3544548.3580871)

- Namnakani, Sinrattanavong, Abdrabou, Bulling, Alt, Khamis, 2023. GazeCast: Using Mobile Devices to Allow Gaze-based Interaction on Public Displays. In Proceedings of the 2023 Symposium on Eye Tracking Research and Application (ETRA '23), DOI: [10.1145/3588015.3589663](https://doi.org/10.1145/3588015.3589663)

- Colley, Wanner, R√§dler, R√∂tzer, Frommel, Hirzle, Jansen, Rukzio, 2024. Efects of a Gaze-Based 2D Platform Game on User Enjoyment,

Perceived Competence, and Digital Eye Strain. In Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems (CHI '24), 
Article No.: 369, [10.1145/3613904.3641909](
https://doi.org/10.1145/3613904.3641909)

- Cai, Hong, Wang, Lu, 2025. GazeSwipe: Enhancing Mobile Touchscreen Reachability through Seamless Gaze and Finger-Swipe Integration. In Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems (CHI '25), DOI: [10.1145/3706598.3713739](https://doi.org/10.1145/3706598.3713739)


<br/>


## üìè Proxemic & Spatially-Aware Interaction


### General


- Hall, 1966. The Hidden Dimension. Anchor Books [üìñ](proxemic/1966-Hall%20The%20Hidden%20Dimension.pdf)

- Ballendat, Marquardt, Greenberg, 2010. Proxemic interaction: Designing for a Proximity and Orientation-Aware Environment. In¬†ACM International Conference on Interactive Tabletops and Surfaces¬†(ITS '10), pp.121-130, DOI: [10.1145/1936652.1936676](https://doi.org/10.1145/1936652.1936676) [üìÑ](proxemic/2010-Ballendat%20et%20al.%20-%20Proxemic%20interaction%20designing%20for%20a%20proximity%20and%20orientation-aware%20environment.pdf)

- **Greenberg, Marquardt, Ballendat, Diaz-Marino, Wang, 2011. Proxemic Interactions: The New Ubicomp?.¬†In Interactions¬†18, 1 (January 2011), pp. 42-50, DOI: [10.1145/1897239.1897250](https://doi.org/10.1145/1897239.1897250)** [üìÑ](proxemic/2011-Greenberg%20et%20al.%20-%20Proxemic%20interactions%20the%20new%20ubicomp.pdf)

- Marquardt, Diaz-Marino, Boring, Greenberg, 2011. The Proximity Toolkit: Prototyping Proxemic Interactions in Ubiquitous Computing Ecologies. In¬†Proceedings of the 24th Annual ACM Symposium on User Interface Software and Technology¬†(UIST '11), DOI: [10.1145/2047196.2047238](https://doi.org/10.1145/2047196.2047238) [üìÑ](proxemic/2011-Marquardt%20et%20al.%20-%20The%20proximity%20toolkit%20prototyping%20proxemic%20interactions%20in%20ubiquitous%20computing%20ecologies.pdf)

- Marquardt, Hinckley, Greenberg, 2012. Cross-device Interaction via Micro-Mobility and F-Formations. In¬†Proceedings of the 25th Annual ACM Symposium on User Interface Software and Technology¬†(UIST '12), pp. 13-22, DOI: [10.1145/2380116.2380121](https://doi.org/10.1145/2380116.2380121) [üìÑ](proxemic/2012-Marquardt%20et%20al.%20-%20Cross-device%20interaction%20via%20micro-mobility%20and%20f-formations.pdf)

- Marquardt, 2013. Proxemic Interactions in Ubiquitous Computing Ecologies. PhD Thesis, University of Calgary [üéì](proxemic/2013-Marquardt%20-%20Proxemic%20Interactions%20in%20Ubiquitous%20Computing%20Ecologies.pdf)

- Greenberg, Boring, Vermeulen, Dostal, 2014. Dark Patterns in Proxemic Interactions: A Critical Perspective. In Proceedings of the 2014 Conference on Designing Interactive Systems (DIS ‚Äò14), pp. 523‚Äì532, DOI: [10.1145/2598510.2598541](https://doi.org/10.1145/2598510.2598541) [üìÑ](proxemic/2014-Greenberg%20et%20al.%20-%20Dark%20Patterns%20in%20Proxemic%20Interaction.pdf)


### Applications


- Brumitt, Meyers, Krumm, Kern, Shafer, 2000. EasyLiving: Technologies for Intelligent Environments. In Proceedings of the 2nd International Symposium on Handheld and Ubiquitous Computing (HUC ‚Äò00), pp. 12‚Äì29, DOI: [10.1007/3-540-39959-3_2](https://doi.org/10.1007/3-540-39959-3_2) [üìÑ](proxemic/2000-Brumitt%20et%20al.%20-%20EasyLiving%20Technologies%20for%20Intelligent%20Environments.pdf)

- Vogel & Balakrishnan, 2004. Interactive Public Ambient Displays: Transitioning from Implicit to Explicit, Public to Personal, Interaction with Multiple Users. In Proceedings of the 17th Annual ACM Symposium on User Interface Software and Technology (UIST '04), pp. 137‚Äì146, DOI: [10.1145/1029632.1029656](https://doi.org/10.1145/1029632.1029656) [üìÑ](proxemic/2004-V%7E1.PDF)

- Ju, Lee, Klemmer, 2008. Range: Exploring Implicit Interaction Through Electronic Whiteboard Design. In Proceedings of the 2008 ACM Conference on Computer Supported Cooperative Work (CSCW ‚Äò08), pp. 17‚Äì26, DOI: [10.1145/1460563.1460569](https://doi.org/10.1145/1460563.1460569) [üìÑ](proxemic/2008-Ju%20et%20al.%20-%20Range%20exploring%20implicit%20interaction%20through.pdf)

- Annett, Grossman, Wigdor, Fitzmaurice, 2011. Medusa: A Proximity-Aware Multi-Touch Tabletop. In Proceedings of the 24th Annual ACM Symposium on User Interface Software and Technology (UIST ‚Äò11), pp. 337‚Äì346, DOI: [10.1145/2047196.2047240](https://doi.org/10.1145/2047196.2047240) [üìÑ](proxemic/2011-Annett%20et%20al.%20-%20Medusa%20A%20Proximity-Aware%20Multi-touch%20Tabletop.pdf)

- Chen, Boring, Carpendale, Tang, Greenberg, 2012. SPALENDAR: Visualizing a Group‚Äôs Calendar Events over a Geographic Space on a Public Display. In Proceedings of the 11th International Working Conference on Advanced Visual Interfaces (AVI ‚Äô12), DOI: [10.11575/PRISM/30760](https://dx.doi.org/10.11575/PRISM/30760) [üìÑ](proxemic/2012-Chen%20-%20SPALENDAR%20Visualizing%20a%20Group's%20Calendar%20Events%20over%20a%20Geographic%20Space%20on%20a%20Public%20Display.pdf)

- Wang, Boring, Greenberg, 2012. Proxemic Peddler: A Public Advertising Display That Captures and Preserves the Attention of a Passerby. In Proceedings of the 2012 International Symposium on Pervasive Displays (PerDis ‚Äò12), Article 3, DOI: [10.1145/2307798.2307801](https://doi.org/10.1145/2307798.2307801) [üìÑ](proxemic/2012-Wang%20-%20Proxemic%20Peddler%20A%20Public%20Advertising%20Display%20that%20Captures%20and%20Preserves%20the%20Attention%20of%20a%20Passerby.pdf)

- Aseniero, Tang, Carpendale, Greenberg, 2013. Showing Real-time Recommendations to Explore the Stages of Reflection and Action. Technical Report #2013-1040-07, Department of Computer Science, University of Calgary [üìÑ](proxemic/2013-Aseneiro%20-%20Showing%20Real-time%20Recommendations.pdf)

- Streitz, Prante, R√∂cker, Van Alphen, Magerkurth, Stenzel, Plewe, 2013. Ambient Displays and Mobile Devices for the Creation of Social Architectural Spaces. In Public and Situated Displays - Social and Interactional Aspects of Shared Display Technologies, pp. 387-409, DOI: [10.1007/978-94-017-2813-3_16](https://doi.org/10.1007/978-94-017-2813-3_16) [üìÑ](proxemic/2013-Streitz%20et%20al.%20-%20Ambient%20Displays%20and%20Mobile%20Devices%20for%20the%20Creation%20of%20Social%20Architectural%20Spaces.pdf)

- Mueller, Stellmach, Greenberg, Dippon, Boll, Garner, Khot, Naseem, Altimira, 2014. Proxemics Play: Understanding Proxemics for Designing Digital Play Experiences. In Proceedings of the 2014 Conference on Designing Interactive Systems (DIS ‚Äò14), pp. 533‚Äì542, DOI: [10.1145/2598510.2598532](https://doi.org/10.1145/2598510.2598532) [üìÑ](proxemic/2014-Mueller%20-%20Proxemics%20play%20understanding%20proxemics%20for%20designing%20digital%20play%20experiences.pdf)

- R√§dle, Jetter, Marquardt, Reiterer, Rogers, 2014. HuddleLamp: Spatially-Aware Mobile Displays for Ad-hoc Around-the-Table Collaboration. In Proceedings of the 9th ACM International Conference on Interactive Tabletops and Surfaces (ITS '14), pp. 45-54, DOI: [10.1145/2669485.2669500](https://doi.org/10.1145/2669485.2669500) [üìÑ](proxemic/2014-R%C3%A4dle%20et%20al.%20-%20HuddleLamp%20Spatially-Aware%20Mobile%20Displays%20for%20Ad-hoc%20Around-the-Table%20Collaboration.pdf)

- Kister, Reipschl√§ger, Matulic, Dachselt, 2015. BodyLenses: Embodied Magic Lenses and Personal Territories for Wall Displays. In Proceedings of the 2015 International Conference on Interactive Tabletops & Surfaces (ITS ‚Äò15), pp. 117‚Äì126, DOI: [10.1145/2817721.2817726](https://doi.org/10.1145/2817721.2817726) [üìÑ](proxemic/2015-Kister%20et%20al.%20-%20BodyLenses%20%E2%80%93%20Embodied%20Magic%20Lenses%20and%20Personal%20Territories%20for%20Wall%20Displays..pdf)

- Ledo, Greenberg, Marquardt, Boring, 2015. Proxemic-Aware Controls: Designing Remote Controls for Ubiquitous Computing Ecologies. In Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services (MobileHCI '15), pp. 187‚Äì198, DOI: [10.1145/2785830.2785871](https://doi.org/10.1145/2785830.2785871) [üìÑ](proxemic/2015-Ledo%20et%20al.%20-%20Proxemic-Aware%20Controls%20Designing%20Remote%20Controls%20for%20Ubiquitous%20Computing%20Ecologies.pdf)

- Vermeulen, Luyten, Coninx, Marquardt, Bird, 2015. Proxemic Flow: Dynamic Peripheral Floor Visualizations for Revealing and Mediating Large Surface Interactions. In Proceedings of the 15th IFIP TC.13 International Conference on Human-Computer Interaction (INTERACT 2015). Lecture Notes in Computer Science, vol 9299, DOI: [10.1007/978-3-319-22723-8_22](https://doi.org/10.1007/978-3-319-22723-8_22) [üìÑ](proxemic/2015-V%7E1.PDF)

- Houben, Vermeulen, Klokmose, Sch√∂ning, Marquardt, and Reiterer. 2016. Cross-Surface: Challenges and Opportunities of Spatial and Proxemic Interaction. In Proceedings of the 2016 ACM International Conference on Interactive Surfaces and Spaces (ISS '16),  pp. 509‚Äì51, DOI: [10.1145/2992154.2996360](https://doi.org/10.1145/2992154.2996360) [üìÑ](proxemic/2016-Houben%20et%20al.%20-%20Cross-Surface%20Challenges%20and%20Opportunities%20of%20Spatial%20and%20Proxemic%20Interaction.pdf)

- Porcheron, Lucero, Quigley, Marquardt, Clawson, O'Hara, 2016. Proxemic Mobile Collocated Interactions. In Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems (CHI EA '16), pp. 3309‚Äì3316, DOI: [10.1145/2851581.2856471](https://doi.org/10.1145/2851581.2856471) [üìÑ](proxemic/2016-Porcheron%20et%20al.%20-%20Proxemic%20Mobile%20Collocated%20Interactions.pdf)

- Tong, Serna, Pageaud, George, Tabard, 2016. It's Not how you Stand, it's how you Move: F-Formations and Collaboration Dynamics in a Mobile Learning Game. In Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services (MobileHCI ‚Äò16), pp. 318‚Äì329, DOI: [10.1145/2935334.2935343](https://doi.org/10.1145/2935334.2935343) [üìÑ](proxemic/2016-T%7E1.PDF)

- Marquardt, Riche, Holz, Romat, Pahud, Brudy, Ledo, Park, Nicholas, Seyed, Ofek, Lee, Buxton, Hinckley, 2021. AirConstellations: In-Air Device Formations for Cross-Device Interaction via Multiple Spatially-Aware Armatures. In Proceedings of the 34th Annual ACM Symposium on User Interface Software and Technology (UIST '21), pp. 1252-1268, DOI: [10.1145/3472749.3474820](https://doi.org/10.1145/3472749.3474820) [üìÑ](proxemic/2021-Marquardt%20et%20al.%20-%20AirConstellations.pdf)

