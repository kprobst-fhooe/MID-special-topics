# Special Topics in Multimodal Interaction

A collection of essential papers and books on diverse topics in Human-Computer Interaction (HCI), specifically in the scope of multimodal interaction. Papers are mainly taken from representative conferences the field of Human-Computer Interaction, such as:

- International Conference on Human Factors in Computing Systems (CHI)
- International Conference on Human-Computer Interaction with Mobile Devices and Services (MobileHCI)
- International Symposium on User Interface Software and Technology (UIST)
- International Conference on Interactive Surfaces and Spaces (ISS)
- International Conference on Tangible, Embedded, and Embodied Interaction (TEI) 
- International Conference on Designing Interactive Systems (DIS)
- International Conference on Human-Computer Interaction (INTERACT)
- International Conference on Mobile and Ubiquitous Multimedia (MUM)
- International Conference on Interactive Media Experiences (IMX)
- International Conference On Computer-Supported Cooperative Work And Social Computing (CSCW)

**Special Topics included:**

- üëã [Gestural Interaction](#-gestural-interaction)
- üß± [Tangible Interaction](#-tangible-interaction)
- üí¨ [Voice Interaction](#-voice-interaction)
- üëÅÔ∏è [Gaze Interaction](#%EF%B8%8F-gaze-interaction)
- üìè [Proxemic & Spatially-Aware Interaction](#-proxemic--spatially-aware-interaction)


<br/>


## ‚ú® Multimodal Interaction


- Oviatt, 1999. Ten Myths of Multimodal Interaction. In Communications of the ACM 42, 11, pp. 74‚Äì81, DOI: [10.1145/319382.319398](https://doi.org/10.1145/319382.319398)

- Oviatt, 2003. Advances in Robust Multimodal Interface Design. In IEEE Computer Graphics and Applications 23, DOI: [10.1109/MCG.2003.1231179](https://doi.org/10.1109/MCG.2003.1231179)

- Reeves, Lai, Larson, Oviatt, Balaji, Buisine, Collings, Cohen, Kraal, Martin, McTear, Raman, Stanney, Su, Wang, 2004. Guidelines for Multimodal User Interface Design. In Communications of the ACM 47, 1, pp. 57‚Äì59, DOI: [10.1145/962081.962106](https://doi.org/10.1145/962081.962106)

- Benford, Schn√§delbach, Koleva, Anastasi, Greenhalgh, Rodden, Green, Ghali, Pridmore, Gaver, Boucher, Walker, Pennington, Schmidt, Gellersen, Steed, 2005. Expected, Sensed, and Desired: A Framework for Designing Sensing-Based Interaction. In ACM Transactions on Computer-Human Interaction 12, 1, pp. 3‚Äì30, DOI: [10.1145/1057237.1057239](https://doi.org/10.1145/1057237.1057239)

- Klemmer, Hartmann, Takayama, 2006. How Bodies Matter: Five Themes for Interaction Design. In Proceedings of the 6th Conference on Designing Interactive Systems (DIS ‚Äò06), pp. 140‚Äì149, DOI: [10.1145/1142405.1142429](https://doi.org/10.1145/1142405.1142429)

- Tzovaras 2008. Multimodal User Interfaces ‚Äì From Signals to Interaction. Springer 

- Dumas, Lalanne, Oviatt, 2009. Multimodal Interfaces: A Survey of Principles, Models and Frameworks. In: Human Machine Interaction. Lecture Notes in Computer Science, vol. 5440. DOI: [810.1007/978-3-642-00437-7_1](https://doi.org/10.1007/978-3-642-00437-7_1)

- Shaked, Winter, 2016. Design of Multimodal Mobile Interfaces. DOI: [10.1515/9781501502736](https://doi.org/10.1515/9781501502736)

- Oviatt, Schuller, Cohen, Sonntag, Potamianos, Kr√ºger, 2017. The Handbook of Multimodal-Multisensor Interfaces: Foundations, User Modeling, and Common Modality Combinations - Volume 1. DOI: [10.1145/3015783](https://doi.org/10.1145/3015783)

- Cheryl Platz, 2020. Design Beyond Devices: Creating Multimodal, Cross-Device Experiences. Rosenfeld Media 


<br/>


## üëã Gestural Interaction


### General

- Karam & Schraefel, 2005. A Taxonomy of Gestures in Human Computer Interactions [üìÑ](gesture/2005-Karam%20et%20al.%20-%20A%20Taxonomy%20of%20Gestures%20in%20Human%20Computer%20Interactions.pdf)

- Saffer, 2008. Designing Gestural Interfaces: Touchscreens and Interactive Devices. O'Reilly Media [üìñ](gesture/2009-Saffer%20-%20Designing%20Gestural%20Interfaces.pdf)

- Norman & Nielsen, 2010. Gestural Interfaces: A Step Backward in Usability. In Interactions 17, 5, pp. 46‚Äì49, doi.org/10.1145/1836216.1836228 [üìÑ](gesture/2010-Norman%20et%20al.%20-%20Gestural%20interfaces%20a%20step%20backward%20in%20usability.pdf)

- Van den Hoven, Mazalek, 2011. Grasping Gestures: Gesturing with Physical Artifacts. In Artificial intelligence for Engineering Design Analysis and Manufacturing¬†25(3), pp. 255-271, DOI: [10.1017/S0890060411000072](https://doi.org/10.1017/S0890060411000072) [üìÑ](gesture/2010-VanDenHoven%20et%20al.%20-%20Grasping%20gestures%20Gesturing%20with%20physical%20artifacts.pdf)

- **Wigdor & Wixon, 2011. Brave NUI World: Designing Natural User Interfaces for Touch and Gesture. Morgan Kaufmann Publishers [üìñ](gesture/2011-Wigdor%20et%20al.%20-%20Brave%20NUI%20World.pdf)**

- Zhai, Kristensson, Appert, Andersen, Cao, 2012. Foundational Issues in Touch-Surface Stroke Gesture Design ‚Äî An Integrative Review. In Foundations and Trends in Human-Computer Interaction, vol. 5, no. 2, pp. 97‚Äì205 [üìÑ](gesture/2012-Zhai%20et%20al.%20-%20Foundational%20Issues%20in%20Touch-Surface%20Stroke%20Gesture%20Design%20%E2%80%94%20An%20Integrative%20Review.pdf)

- LaViola, 2013. 3D Gestural Interaction: The State of the Field. In International Scholarly Research Notices,¬†Volume¬†2013, Article ID¬†514641, DOI: [10.1155/2013/514641](https://doi.org/10.1155/2013/514641) [üìÑ](gesture/2013-LaViola%20-%203D%20Gestural%20Interaction%20The%20State%20of%20the%20Field.pdf)



### Applications Mid-Air

- Baudel, Beaudouin-Lafon, 1993. Charade: remote control of objects using free-hand gestures. In Commun. ACM 36, 7 (July 1993), pp. 28‚Äì35, DOI: [10.1145/159544.159562](https://doi.org/10.1145/159544.159562) [üìÑ](gesture/mid-air/1993-Baudel%20et%20al.%20-%20Charade%20Remote%20Control%20of%20Objects%20Using%20Free-Hand%20Gestures.pdf)

- Dachselt & Buchholz, 2009. Natural throw and tilt interaction between mobile phones and distant displays. In CHI '09 Extended Abstracts on Human Factors in Computing Systems (CHI EA ‚Äò09), pp. 3253‚Äì3258, DOI: [10.1145/1520340.1520467] [üìÑ](gesture/mid-air/2009-Dachselt%20et%20al.%20-%20Natural%20Throw%20and%20Tilt%20Interaction%20between%20Mobile%20Phones%20and%20Distant%20Displays.pdf)

- Fourney, Terry, Mann, 2010. Gesturing in the wild: understanding the effects and implications of gesture-based interaction for dynamic presentations. In Proceedings of the 24th BCS Interaction Specialist Group Conference (BCS ‚Äò10), pp. 230‚Äì240 [üìÑ](gesture/mid-air/2010-Fourney%20et%20al.%20-%20Gesturing%20in%20the%20Wild.pdf)

- Gustafson, Bierwirth, Baudisch, 2010. Imaginary interfaces: spatial interaction with empty hands and without visual feedback. In Proceedings of the 23nd annual ACM symposium on User interface software and technology (UIST ‚Äò10), pp. 3‚Äì12, DOI: [10.1145/1866029.1866033](gesture/mid-air/2010-Gustafson%20et%20al.%20-%20Imaginary%20Interfaces%20Spatial%20Interaction%20with%20Empty%20Hands%20and%20without%20Visual%20Feedback.pdf)

- Gustafson, Holz, Baudisch, 2011. Imaginary phone: learning imaginary interfaces by transferring spatial memory from a familiar device. In Proceedings of the 24th annual ACM symposium on User interface software and technology(UIST '11), pp. 283‚Äì292, DOI: [10.1145/2047196.2047233](https://doi.org/10.1145/2047196.2047233)[üìÑ](gesture/mid-air/2011-Gustafson%20et%20al.%20-%20Imaginary%20phone%20learning%20imaginary%20interfaces%20by%20transferring%20spatial%20memory.pdf)

- Han, Alexander, Karnik, Irani, Subramanian, 2011. Kick: investigating the use of kick gestures for mobile interactions. In Proceedings of the 13th International Conference on Human Computer Interaction with Mobile Devices and Services (MobileHCI ‚Äò11), pp. 29‚Äì32, DOI: [10.1145/2037373.2037379](https://doi.org/10.1145/2037373.2037379) [üìÑ](gesture/mid-air/2011-Han%20et%20al.%20-%20Kick%20Investigating%20the%20use%20of%20kick%20gestures%20for%20mobile%20interactions.pdf)

- Bailly, M√ºller, Rohs, Wigdor, Kratz, 2012. ShoeSense: a new perspective on gestural interaction and wearable applications. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI ‚Äò12), pp. 1239‚Äì1248, DOI: [10.1145/2207676.2208576](https://doi.org/10.1145/2207676.2208576) [üìÑ](gesture/mid-air/2012-Bailly%20et%20al.%20-%20ShoeSense%20a%20new%20perspective%20on%20gestural%20interaction%20and%20wearable%20applications.pdf)

- Cohn, Morris, Patel, and Tan, 2012. Humantenna: using the body as an antenna for real-time whole-body interaction. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI ‚Äò12), pp. 1901‚Äì1910, DOI: [10.1145/2207676.2208330](https://doi.org/10.1145/2207676.2208330) [üìÑ](gesture/mid-air/2012-Cohn%20et%20al.%20-%20Humantenna%20Using%20the%20Body%20as%20an%20Antenna%20for%20Real-Time%20Whole-Body%20Interaction.pdf)

- Song, S√∂r√∂s, Pece, Fanello, Izadi, Keskin, Hilliges, 2014. In-air gestures around unmodified mobile devices. In Proceedings of the 27th annual ACM symposium on User interface software and technology (UIST ‚Äò14), pp. 319‚Äì329, DOI: [10.1145/2642918.2647373](https://doi.org/10.1145/2642918.2647373) [üìÑ](gesture/mid-air/2014-Song%20et%20al.%20-%20In-air%20gestures%20around%20unmodified%20mobile%20devices.pdf)

- Chan, Hsieh, Chen, Yang, Huang, Liang, Chen. 2015. Cyclops: Wearable and Single-Piece Full-Body Gesture Input Devices. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems (CHI ‚Äò15), pp. 3001‚Äì3009, DOI: [10.1145/2702123.2702464](https://doi.org/10.1145/2702123.2702464) [üìÑ](gesture/mid-air/2015-Chan%20et%20al.%20-%20Cyclops%20Wearable%20and%20Single-Piece%20Full-Body%20Gesture%20Input%20Devices.pdf)

- Liu, Nancel, Vogel, 2015. Gunslinger: Subtle Arms-down Mid-air Interaction. In Proceedings of the 28th Annual ACM Symposium on User Interface Software & Technology (UIST ‚Äò15), pp. 63‚Äì71, DOI: [10.1145/2807442.2807489](https://doi.org/10.1145/2807442.2807489) [üìÑ](gesture/mid-air/2015-Liu%20et%20al.%20-%20Gunslinger%20Subtle%20Arms-down%20Mid-air%20Interaction.pdf)

- Silpasuwanchai, Ren, 2015. Designing concurrent full-body gestures for intense gameplay. In International Journal of Human-Computer Studies 80, DOI: 810.1016/j.ijhcs.2015.02.010](doi.org/10.1016/j.ijhcs.2015.02.010) [üìÑ](gesture/mid-air/2015-Silpasuwanchai%20et%20al.%20-%20Designing%20concurrent%20full-body%20gestures%20for%20intense%20gameplay.pdf)

- Lien, Gillian, Karagozler, Amihood, Schwesig, Olson, Raja, Poupyrev, 2016. Soli: ubiquitous gesture sensing with millimeter wave radar. In ACM Trans. Graph. 35, 4, Article 142 (July 2016), DOI: [10.1145/2897824.2925953](https://doi.org/10.1145/2897824.2925953) [üìÑ](gesture/mid-air/2016-Lien%20et%20al.%20-%20Soli%20Ubiquitous%20Gesture%20Sensing%20with%20Millimeter%20Wave%20Radar.pdf)

- Detjen, Faltaous, Geisler, Schneegass, 2019. User-Defined Voice and Mid-Air Gesture Commands for Maneuver-based Interventions in Automated Vehicles. In Proceedings of Mensch und Computer 2019 (MuC‚Äô19), pp. 341‚Äì348, DOI: [10.1145/3340764.3340798](https://doi.org/10.1145/3340764.3340798) [üìÑ](gesture/mid-air/2019-Detjen%20et%20al.%20-%20User-Defined%20Voice%20and%20Mid-Air%20Gesture%20Commands%20for%20Maneuver-based%20Interventions%20in%20Automated%20Vehicles.pdf)

- Lopes, Relvas, Paulo, Rekik, Grisoni, Jorge, 2019. FEETICHE: FEET Input for Contactless Hand gEsture Interaction. In The 17th International Conference on Virtual-Reality Continuum and its Applications in Industry (VRCAI '19), Article 29, DOI: [10.1145/3359997.3365704](https://doi.org/10.1145/3359997.3365704) [üìÑ](gesture/mid-air/2019-Lopes%20et%20al.%20-%20FEETICHE%20FEET%20Input%20for%20Contactless%20Hand%20gEsture%20Interaction.pdf)

- Hermann, Pl√ºckthun, Dogang√ºn, Hesenius, 2022. User-Defined Gesture and Voice Control in Human-Drone Interaction for Police Operations. In Proceedings of the Nordic Human-Computer Interaction Conference (NordiCHI '22), DOI: [10.1145/3546155.3546661](https://doi.org/10.1145/3546155.3546661) [üìÑ](gesture/mid-air/2022-Hermann%20-%20User-Defined%20Gesture%20and%20Voice%20Control%20in%20Human-Drone%20Interaction.pdf)
  
- ≈ûiean, PamparƒÉu, Vatavu, 2022. Scenario-based Exploration of Integrating Radar Sensing Into Everyday Objects for Free-Hand Television Control. In Proceedings ACM International Conference on Interactive Media Experiences (IMX '22), pp. 357‚Äì362, DOI: [10.1145/3505284.3532982](https://doi.org/10.1145/3505284.3532982) [üìÑ](gesture/mid-air/2022-Siean%20et%20al.%20-%20Integrating%20Radar%20Sensing%20into%20Everyday%20Objects%20for%20Free-Hand%20Television%20Control.pdf)

- Chang, Chen, Dong, Cai, Yan, Cai, Zhou, Zhou, Gong, 2024. "It Must Be Gesturing Towards Me": Gesture-Based Interaction between Autonomous Vehicles and Pedestrians. In Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems (CHI '24), DOI: [10.1145/3613904.3642029](https://doi.org/10.1145/3613904.3642029)

- Hosseini, M√ºller, Boll, 2024. Controlling the Rooms: How People Prefer Using Gestures to Control Their Smart Homes. In Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems (CHI '24), DOI: [10.1145/3613904.3642687](https://doi.org/10.1145/3613904.3642687) 



### Applications On-Surface

- Kurtenbach, 1993. The Design and Evaluation of Marking Menus. PhD Thesis, University of Toronto [üéì](gesture/on-surface/1993-Kurtenbach%20-%20The%20Design%20and%20Evaluation%20of%20Marking%20Menus.pdf)

- Rekimoto, 2002. SmartSkin: an infrastructure for freehand manipulation on interactive surfaces. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI ‚Äò02), pp. 113‚Äì120, DOI: [10.1145/503376.503397](https://doi.org/10.1145/503376.503397) [üìÑ](gesture/on-surface/2002-Rekimoto%20-%20SmartSkin%20An%20Infrastructure%20for%20Freehand%20Manipulation%20on.pdf)

- Wu & Balakrishnan, 2003. Multi-finger and whole hand gestural interaction techniques for multi-user tabletop displays. In Proceedings of the 16th annual ACM symposium on User interface software and technology (UIST ‚Äò03), pp. 193‚Äì202, DOI: [10.1145/964696.964718](https://doi.org/10.1145/964696.964718) [üìÑ](gesture/on-surface/2003-W%7E1.PDF)

- Ringel Morris, Huang, Paepcke, Winograd, 2006. Cooperative gestures: multi-user gestural interactions for co-located groupware. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI ‚Äò06), pp. 1201‚Äì1210, DOI: [10.1145/1124772.1124952](https://doi.org/10.1145/1124772.1124952) [üìÑ](gesture/on-surface/2006-Ringel-Morris%20et%20al.%20-%20Cooperative%20Gestures%20Multi-User%20Gestural%20Interactions%20for%20Co-located%20Groupware.pdf)

- Wigdor, Leigh, Forlines, Shipman, Barnwell, Balakrishnan, Shen, 2006. Under the table interaction. In Proceedings of the 19th annual ACM symposium on User interface software and technology (UIST ‚Äò06), pp. 259‚Äì268, DOI: [10.1145/1166253.1166294](https://doi.org/10.1145/1166253.1166294) [üìÑ](gesture/on-surface/2006-Wigdor%20et%20al.%20-%20Under%20the%20table%20interaction.pdf)

- Daiber, Sch√∂ning, Kr√ºger, 2009. Whole Body Interaction with Geospatial Data. In Proceedings Smart Graphics, 9th International Symposium (SG '09). DOI: [10.1007/978-3-642-02115-2_7](https://doi.org/10.1007/978-3-642-02115-2_7) [üìÑ](gesture/on-surface/2009-Daiber%20et%20al.%20-%20Whole-Body%20Interaction%20with%20Geospatial%20Data.pdf)

- Augsten, Kaefer, Meusel, Fetzer, Kanitz, Stoff, Becker, Holz, Baudisch, 2010. Multitoe: high-precision interaction with back-projected floors based on high-resolution multi-touch input. In Proceedings of the 23nd annual ACM symposium on User interface software and technology (UIST ‚Äò10), pp. 209‚Äì218, DOI: [10.1145/1866029.1866064](https://doi.org/10.1145/1866029.1866064) [üìÑ](gesture/on-surface/2010-A%7E1.PDF)

- Harrison, Tan, Morris, 2010. Skinput: appropriating the body as an input surface. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI ‚Äò10), pp. 453‚Äì462, DOI: [10.1145/1753326.1753394](https://doi.org/10.1145/1753326.1753394) [üìÑ](gesture/on-surface/2010-Harrison%20et%20al.%20-%20Skinput%20Appropriating%20the%20Body%20as%20an%20Input%20Surface.pdf)

- D√∂ring, Kern, Marshall, Pfeiffer, Sch√∂ning, Gruhn, Schmidt, 2011. Gestural interaction on the steering wheel: reducing the visual demand. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI ‚Äò11), pp. 483‚Äì492, DOI: [10.1145/1978942.1979010](https://doi.org/10.1145/1978942.1979010) [üìÑ](gesture/on-surface/2011-D%C3%B6ring%20-%20Gestural%20interaction%20on%20the%20steering%20wheel%20-%20Reducing%20the%20visual%20demand.pdf)

- Harrison, Benko, Wilson. 2011, OmniTouch: wearable multitouch interaction everywhere. In Proceedings of the 24th annual ACM symposium on User interface software and technology (UIST ‚Äò11), pp. 441‚Äì450, DOI: [10.1145/2047196.2047255](https://doi.org/10.1145/2047196.2047255) [üìÑ](gesture/on-surface/2011-Harrison%20et%20al.%20-%20OmniTouch%20Wearable%20Multitouch%20Interaction%20Everywhere.pdf)

- Harrison, Schwarz, Hudson, 2011. TapSense: enhancing finger interaction on touch surfaces. In Proceedings of the 24th annual ACM symposium on User interface software and technology (UIST '11), pp. 627‚Äì636, DOI: [10.1145/2047196.2047279](https://doi.org/10.1145/2047196.2047279) [üìÑ](gesture/on-surface/2011-Harrison%20et%20al.%20-%20TapSense%20enhancing%20finger%20interaction%20on%20touch%20surfaces.pdf)

- Jota, Lopes, Wigdor, Jorge. 2014. Let's kick it: how to stop wasting the bottom third of your large screen display. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI ‚Äò14), pp. 1411‚Äì1414, DOI: [10.1145/2556288.2557316](https://doi.org/10.1145/2556288.2557316) [üìÑ](gesture/on-surface/2014-Jota%20et%20al.%20-%20Let%E2%80%99s%20Kick%20It%20How%20to%20Stop%20Wasting%20the%20Bottom%20Third%20of%20Your%20Large%20Scale%20Display.pdf)

- Vo, Lecolinet, Guiard, 2014. Belly gestures: body centric gestures on the abdomen. In Proceedings of the 8th Nordic Conference on Human-Computer Interaction: Fun, Fast, Foundational (NordiCHI ‚Äò14), pp. 687‚Äì696, DOI: [10.1145/2639189.2639210](https://doi.org/10.1145/2639189.2639210) [üìÑ](gesture/on-surface/2014-Vo%20et%20al.%20-%20Belly%20Gestures%20Body%20Centric%20Gestures%20on%20the%20Abdomen.pdf)

- Fukahori, Sakamoto, Igarashi, 2015. Exploring Subtle Foot Plantar-based Gestures with Sock-placed Pressure Sensors. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems (CHI ‚Äò15), pp. 3019‚Äì3028, DOI: [10.1145/2702123.2702308](https://doi.org/10.1145/2702123.2702308) [üìÑ](gesture/on-surface/2015-Fukahori%20et%20al.%20-%20Exploring%20Subtle%20Foot%20Plantar-based%20Gestures%20with%20Sock-placed%20Pressure%20Sensors.pdf)

- Sridhar, Markussen, Oulasvirta, Theobalt, Boring, 2017. WatchSense: On- and Above-Skin Input Sensing through a Wearable Depth Sensor. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (CHI '17), pp. 3891‚Äì3902, DOI: [10.1145/3025453.3026005](gesture/on-surface/2017-Sridhar%20et%20al.%20-%20WatchSense%20On-%20and%20Above-Skin%20Input%20Sensing%20through%20a%20Wearable%20Depth%20Sensor.pdf)

- Quinn, Lee, Barnhart, Zhai, 2019. Active Edge: Designing Squeeze Gestures for the Google Pixel 2. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems (CHI ‚Äò19), Paper 274, DOI: [10.1145/3290605.3300504](https://doi.org/10.1145/3290605.3300504) [üìÑ](gesture/on-surface/2019-Quinn%20et%20al.%20-%20Active%20Edge%20Designing%20Squeeze%20Gestures%20for%20the%20Google%20Pixel%202.pdf)

- Wang & Grossman, 2020. BlyncSync: Enabling Multimodal Smartwatch Gestures with Synchronous Touch and Blink. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems (CHI ‚Äò20), DOI: [10.1145/3313831.3376132](https://doi.org/10.1145/3313831.3376132) [üìÑ](gesture/on-surface/2020-Wang%20et%20al.%20-%20BlyncSync%20Enabling%20Multimodal%20Smartwatch%20Gestures%20with%20Synchronous%20Touch%20and%20Blink.pdf)

- Mlakar, Haberfellner, Jetter, Haller, 2021. Exploring Affordances of Surface Gestures on Textile User Interfaces. In Proceedings of the International Conference on Designing Interactive Systems (DIS '21), pp. 1159‚Äì1170, DOI: [10.1145/3461778.3462139](https://doi.org/10.1145/3461778.3462139) [üìÑ](gesture/on-surface/2021-Mlakar%20et%20al.%20-%20Affordances%20of%20Surface%20Gestures%20on%20Textile%20User%20Interfaces.pdf)

- Parthiban, Maes, Sellier, Sluyters, Vanderdonckt, 2022. Gestural-Vocal Coordinated Interaction on Large Displays. In Companion of the 2022 ACM SIGCHI Symposium on Engineering Interactive Computing Systems (EICS '22), pp. 26-32, DOI: [10.1145/3531706.3536457](https://doi.org/10.1145/3531706.3536457) [üìÑ](gesture/on-surface/2022-Parthiban%20-%20Gestural-Vocal%20Coordinated%20Interaction%20on%20Large%20Displays.pdf)

- Shen, Harrison, 2022. Pull Gestures with Coordinated Graphics on Dual-Screen Devices. In Proceedings of the 2022 International Conference on Multimodal Interaction (ICMI '22), pp. 270-277, DOI: [10.1145/3536221.3556620](https://doi.org/10.1145/3536221.3556620) [üìÑ](gesture/on-surface/2022-Shen%20-%20Pull%20Gestures%20with%20Coordinated%20Graphics%20on%20Dual-Screen%20Devices.pdf)

- Andrei, Bilius, Vatavu, 2024. Take a Seat, Make a Gesture: Charting User Preferences for On-Chair and From-Chair Gesture Input. In Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems (CHI '24), DOI: [10.1145/3613904.3642028](https://doi.org/10.1145/3613904.3642028)


<br/>



## üß± Tangible Interaction


### General


- Fitzmaurice, Ishii, Buxton. 1995. Bricks: Laying the Foundations for Graspable User Interfaces. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI ‚Äò95), pp. 442‚Äì449, DOI: [10.1145/223904.223964](https://doi.org/10.1145/223904.223964) [üìÑ](tangible/1995-Fitzmaurice%20et%20al.%20-%20Bricks%20laying%20the%20foundations%20for%20graspable%20user%20interfaces.pdf)

- Ishii & Ullmer, 1997. Tangible Bits: Towards Seamless Interfaces Between People, Bits and Atoms. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI ‚Äô97), pp. 234‚Äì241, DOI: [10.1145/258549.258715](https://doi.org/10.1145/258549.258715) [üìÑ](tangible/1997-Ishii%20et%20al.%20-%20Tangible%20bits%20towards%20seamless%20interfaces%20between%20people%2C%20bits%20and%20atoms.pdf)

- Fishkin, 2004. A Taxonomy for and Analysis of Tangible Interfaces. In Personal Ubiquitous Computing 8, 5 (September 2004), pp. 347‚Äì358 [üìÑ](tangible/2004-Fishkin%20-%20A%20taxonomy%20for%20and%20analysis%20of%20tangible%20interfaces.pdf)

- Ishii, 2008. The Tangible User Interface and its Evolution. In Communications of the ACM 51, 6 (June 2008), pp. 32‚Äì36, DOI: [10.1145/1349026.1349034](https://doi.org/10.1145/1349026.1349034) [üìÑ](tangible/2008-Ishii%20-%20The%20tangible%20user%20interface%20and%20its%20evolution.pdf)

- Shaer & Hornecker, 2010, Tangible User Interfaces: Past, Present, and Future Directions, In Foundations and Trends in Human‚ÄìComputer Interaction: Vol. 3: No. 1‚Äì2, pp. 4-137, DOI: [10.1561/1100000026](https://dx.doi.org/10.1561/1100000026) [üìÑ](tangible/2010-Shaer%20et%20al.%20-%20Tangible%20User%20Interfaces%20Past%2C%20Present%2C%20and%20Future%20Directions.pdf)

- **Ishii, Lakatos, Bonanni, Labrune, 2012. Radical Atoms: Beyond Tangible Bits, Toward Transformable Materials.¬†In ACM Interactions¬†19, 1 (January 2012), pp. 38-51, DOI: [10.1145/2065327.2065337](https://doi.org/10.1145/2065327.2065337)** [üìÑ](tangible/2012-Ishii%20et%20al.%20-%20Radical%20Atoms%2C%20Beyond%20Tangible%20Bits%2C%20Toward%20Transformable%20Materials.pdf)

- Alexander, Roudaut, Steimle, Hornb√¶k, Alonso, Follmer, Merritt, 2018. Grand Challenges in Shape-Changing Interface Research. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI '18), Paper 299, DOI: [10.1145/3173574.3173873](https://doi.org/10.1145/3173574.3173873) [üìÑ](tangible/2018-Alexander%20et%20al.%20-%20Grand%20Challenges%20in%20Shape-Changing%20Interface%20Research.pdf)


### Applications


- Ullmer & Ishii, 1997. The metaDESK: Models and Prototypes for Tangible User Interfaces. In Proceedings of the 10th Annual ACM Symposium on User Interface Software and Technology (UIST '97), pp. 223‚Äì232, DOI: [10.1145/263407.263551](https://doi.org/10.1145/263407.263551) [üìÑ](tangible/1997-Ullmer%20et%20al.%20-%20The%20metaDESK%20models%20and%20prototypes%20for%20tangible%20user%20interfaces.pdf)

- Raffle, Parkes, Ishii, 2004. Topobo: a constructive assembly system with kinetic memory. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI ‚Äò04), pp. 647‚Äì654, DOI: [10.1145/985692.985774](https://doi.org/10.1145/985692.985774) [üìÑ](tangible/2004-Raffles%20et%20al.%20-%20Topobo%20a%20constructive%20assembly%20system%20with%20kinetic%20memory.pdf)

- Jord√†, Geiger, Alonso, Kaltenbrunner, 2007. The reacTable: Exploring the Synergy between Live Music Performance and Tabletop Tangible Interfaces. In Proceedings of the 1st International Conference on Tangible and Embedded interaction (TEI ‚Äò07), pp. 139‚Äì146, DOI: [10.1145/1226969.1226998](https://doi.org/10.1145/1226969.1226998) [üìÑ](tangible/2007-Jorda%20et%20al.%20-%20The%20reacTable%20exploring%20the%20synergy%20between%20live%20music%20performance%20and%20tabletop%20tangible%20interfaces.pdf)

- Zigelbaum, Kumpf, Vazquez, Ishii, 2008. Slurp: Tangibility Spatiality and an Eyedropper. In CHI '08 Extended Abstracts on Human Factors in Computing Systems (CHI EA ‚Äò08), pp. 2565‚Äì2574, DOI: [10.1145/1358628.1358713](https://doi.org/10.1145/1358628.1358713) [üìÑ](tangible/2008-Zigelbaum%20et%20al.%20-%20Slurp%20tangibility%20spatiality%20and%20an%20eyedropper.pdf)

- Cheng, Liang, Chen, Laing, Kuo, 2010. iCon: Utilizing Everyday Objects as Additional, Auxiliary and Instant Tabletop Controllers. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI ‚Äò10), pp. 1155‚Äì1164, DOI: [10.1145/1753326.1753499](https://doi.org/10.1145/1753326.1753499) [üìÑ](tangible/2010-Cheng%20et%20al.%20-%20iCon%20utilizing%20everyday%20objects%20as%20additional%2C%20auxiliary%20and%20instant%20tabletop%20controllers.pdf)

- Spindler, Hauschild, Dachselt, 2010. Towards Making Graphical User Interface Palettes Tangible. In ACM International Conference on Interactive Tabletops and Surfaces (ITS ‚Äò10), pp. 291‚Äì292, DOI: [10.1145/1936652.1936721](https://doi.org/10.1145/1936652.1936721) [üìÑ](tangible/2010-Spindler%20et%20al.%20-%20Towards%20making%20graphical%20user%20interface%20palettes%20tangible.pdf)

- Pedersen & Hornb√¶k, 2011. Tangible Bots: Interaction with Active Tangibles in Tabletop Interfaces. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI ‚Äò11), pp. 2975‚Äì2984, DOI: [10.1145/1978942.1979384](https://doi.org/10.1145/1978942.1979384) [üìÑ](tangible/2011-Pedersen%20et%20al.%20-%20Tangible%20bots%20interaction%20with%20active%20tangibles%20in%20tabletop%20interfaces.pdf)

- Bianchi & Oakley, 2013. Designing Tangible Magnetic Appcessories. In Proceedings of the 7th International Conference on Tangible, Embedded and Embodied Interaction (TEI ‚Äò13), pp. 255‚Äì258, DOI: [10.1145/2460625.2460667](doi.org/10.1145/2460625.2460667) [üìÑ](tangible/2013-Bianchi%20et%20al.%20-%20Designing%20tangible%20magnetic%20appcessories.pdf)

- Follmer, Leithinger, Olwal, Hogge, Ishii, 2013. InFORM: Dynamic Physical Affordances and Constraints through Shape and Object Actuation. In Proceedings of the 26th annual ACM symposium on User interface software and technology (UIST ‚Äö13), pp. 417‚Äì426. DOI: [10.1145/2501988.2502032](https://doi.org/10.1145/2501988.2502032) [üìÑ](tangible/2013-Follmer%20et%20al.%20-%20InFORM%20dynamic%20physical%20affordances%20and%20constraints%20through%20shape%20and%20object%20actuation.pdf)

- Yao, Niiyama, Ou, Follmer, Della Silva, Ishii, 2013. PneUI: Pneumatically Actuated Soft Composite Materials for Shape Changing Interfaces. In Proceedings of the 26th annual ACM symposium on User interface software and technology (UIST ‚Äò13), pp. 13‚Äì22. DOI: [10.1145/2501988.2502037](https://doi.org/10.1145/2501988.2502037) [üìÑ](tangible/2013-Yao%20et%20al.%20-%20PneUI%20Pneumatically%20Actuated%20Soft%20Composite%20Materials%20for%20Shape%20Changing%20Interfaces.pdf)

- Liang, Chan, Tseng, Kuo, Huang, Yang, Chen, 2014. GaussBricks: Magnetic Building Blocks for Constructive Tangible Interactions on Portable Displays. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '14), pp. 3153‚Äì3162. DOI: [10.1145/2556288.2557105 ](https://doi.org/10.1145/2556288.2557105) [üìÑ](tangible/2014-Liang%20et%20al.%20-%20GaussBricks%20magnetic%20building%20blocks%20for%20constructive%20tangible%20interactions%20on%20portable%20displays.pdf)

- Schmidt, Ramakers, Pedersen, Jasper, K√∂hler, Pohl, Rantzsch, Rau, Schmidt, Sterz, Yurchenko, Baudisch, 2014. Kickables: Tangibles for Feet. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI ‚Äò14), pp. 3143‚Äì3152, DOI: [10.1145/2556288.2557016](https://doi.org/10.1145/2556288.2557016) [üìÑ](tangible/2014-Schmidt%20et%20al.%20-%20Kickables%20tangibles%20for%20feet.pdf)

- Valdes, Eastman, Grote, Thatte, Shaer, Mazalek, Ullmer, Konkel, 2014. Exploring the Design Space of Gestural Interaction with Active Tokens through User-Defined Gestures. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI ‚Äò14), pp.4107‚Äì4116, DOI: [10.1145/2556288.2557373](https://doi.org/10.1145/2556288.2557373) [üìÑ](tangible/2014-Valdes%20et%20al.%20-%20Exploring%20the%20design%20space%20of%20gestural%20interaction%20with%20active%20tokens%20through%20user-defined%20gestures.pdf)

- Le Goc, Kim, Parsaei, Fekete, Dragicevic, Follmer, 2016. Zooids: Building Blocks for Swarm User Interfaces. In Proceedings of the 29th Annual Symposium on User Interface Software and Technology (UIST ‚Äò16), pp. 97‚Äì109, DOI:[10.1145/2984511.2984547](https://doi.org/10.1145/2984511.2984547) [üìÑ](tangible/2016-LeGoc%20-%20Zooids%20Building%20Blocks%20for%20Swarm%20User%20Interfaces.pdf)

- Pratte, Seyed, Maurer, 2016. Acquario: A Tangible Spatially-Aware Tool for Information Interaction and Visualization. In Proceedings of the 2016 Symposium on Spatial User Interaction (SUI ‚Äò16), DOI: [10.1145/2983310.2989208](https://doi.org/10.1145/2983310.2989208) [üìÑ](tangible/2016-Pratte%20-%20Acquario%20A%20Tangible%20Spatially-Aware%20Tool%20for%20Information%20Interaction%20and%20Visualization.pdf)

- Leong, Perteneder, Jetter, Haller, 2017. What a Life!: Building a Framework for Constructive Assemblies. In Proceedings of the Eleventh International Conference on Tangible, Embedded, and Embodied Interaction (TEI '17), pp. 57-66, DOI: [10.1145/3024969.3024985](https://doi.org/10.1145/3024969.3024985) [üìÑ](tangible/2017-Leong%20et%20al.%20-%20What%20a%20Life.pdf)

- Villar, Cletheroe, Saul, Holz, Regan, Salandin, Sra, Yeo, Field, Zhang, 2018. Project Zanzibar: A Portable and Flexible Tangible Interaction Platform. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI ‚Äò18), Paper 515, DOI: [10.1145/3173574.3174089](https://doi.org/10.1145/3173574.3174089) [üìÑ](tangible/2018-Villar%20et%20al-%20Project%20Zanzibar%20A%20Portable%20and%20Flexible%20Tangible%20Interaction%20Platform.pdf)

- Yeo, Minami, Rodriguez, Shaker, Quigley, 2018. Exploring Tangible Interactions with Radar Sensing. In Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. 2, 4, Article 200, DOI: [10.1145/3287078](https://doi.org/10.1145/3287078) [üìÑ](tangible/2018-Yeo%20et%20al.%20-%20Exploring%20Tangible%20Interactions%20with%20Radar%20Sensing.pdf)

- Suzuki, Zheng, Kakehi, Yeh, Do, Gross, Leithinger, 2019. ShapeBots: Shape-changing Swarm Robots. In Proceedings of the 32nd Annual ACM Symposium on User Interface Software and Technology (UIST ‚Äò19), pp. 493‚Äì505, DOI: [10.1145/3332165.3347911](https://doi.org/10.1145/3332165.3347911) [üìÑ](tangible/2018-Suzuki%20-%20ShapeBots%20Shape-changing%20Swarm%20Robots.pdf)

- Perteneder, Probst, Leoong, Gassler, Rendl, Parzer, Fluch, Gahleitner, Follmer, Koike, Haller, 2020. Foxels: Build Your Own Smart Furniture. In Proceedings of the Fourteenth International Conference on Tangible, Embedded, and Embodied Interaction (TEI '20), pp. 111-122, DOI: [10.1145/3374920.3374935](https://doi.org/10.1145/3374920.3374935) [üìÑ](tangible/2020-Perteneder%20et%20al.%20-%20Foxels.pdf)



<br/>



## üí¨ Voice Interaction


### General

- Cohen, 2004. Voice User Interface Design, Addison-Wesley [üìñ](voice/2004-Cohen%20-%20Voice%20User%20Interface%20Design.pdf)

- Klein, 2016. Designing for Voice Interfaces, O‚ÄôReilly Media [üìñ](voice/2016-Klein%20Designing%20for%20Voice%20Interfaces.pdf)

- Pearl, 2016. Designing Voice User Interfaces, O‚ÄôReilly Media [üìñ](voice/2016-Pearl%20-%20Designing%20Voice%20User%20Interfaces.pdf)

- Moore, 2017. Is Spoken Language All-or-Nothing? Implications for Future Speech-Based Human-Machine Interaction. In Dialogues with Social Robots. Lecture Notes in Electrical Engineering, vol 427, DOI: [10.1007/978-981-10-2585-3_22 ](https://doi.org/10.1007/978-981-10-2585-3_22)

- Murad, Munteanu, Clark, Cowan, 2018. Design guidelines for hands-free speech interaction. In Proceedings of the 20th International Conference on Human-Computer Interaction with Mobile Devices and Services (MobileHCI ‚Äò18), pp. 269‚Äì276, DOI: [10.1145/3236112.3236149](https://doi.org/10.1145/3236112.3236149)

- **Wei & Landay, 2018. Evaluating Speech-Based Smart Devices Using New Usability Heuristics. In¬†IEEE Pervasive Computing, vol. 17, no. 2, pp. 84-96, DOI: [10.1109/MPRV.2018.022511249](https://doi.10.1109/MPRV.2018.022511249) [üìÑ](voice/2018-Wei%20et%20al.%20-%20Evaluating%20Speech-Based%20Smart%20Devices%20Using%20New%20Usability%20Heuristics.pdf)**

- **Moore & Arar, 2019. Conversational UX Design ‚Äì A Practitioner‚Äôs Guide to the Natural Conversation Framework (Chapter 1)** [üìñ](voice/2019-Moore%20et%20al.%20-%20Conversational%20UX%20Design.pdf)

- Murad, Munteanu, 2019. "I don't know what you're talking about, HALexa": the Case For Voice User Interface Guidelines. In Proceedings of the 1st International Conference on Conversational User Interfaces (CUI '19), Article 9, DOI: [10.1145/3342775.3342795](https://doi.org/10.1145/3342775.3342795)

- Bouzid, Ma, 2022. The Elements of Voice First Style: A Practical Guide to Voice User Interface Design, O'Reilly Media [üìñ](voice/2022-Bouzid%20-%20The%20Elements%20of%20Voice%20First%20Style.pdf)

- **Murad, Candello, Munteanu, 2024. What‚Äôs The Talk on VUI Guidelines? A Meta-Analysis of Guidelines for Voice User Interface Design. In Proceedings of the 5th International Conference on Conversational User Interfac (CUI '23), Article 19, DOI: [10.1145/3571884.3597129](https://doi.org/10.1145/3571884.3597129)**



### Applications


- Oviatt, Cohen, Wu, Vergo, Duncan, Suhm, Bers, Holzman, Winograd, Landay, Larson, Ferro, 2000. Designing the user interface for multimodal speech and pen-based gesture applications: state-of-the-art systems and future research directions. In Hum.-Comput. Interact. 15, 4 (December 2000), pp. 263‚Äì322, DOI: [10.1207/S15327051HCI1504_1](https//doi.org/10.1207/S15327051HCI1504_1)

- Igarashi & Hughes, 2001. Voice as sound: using non-verbal voice input for interactive control. In Proceedings of the 14th annual ACM symposium on User interface software and technology (UIST ‚Äò01), pp. 155‚Äì156, DOI: [10.1145/502348.502372](https//doi.org/10.1145/502348.502372)

- Krum, Omoteso, Ribarsky, Starner, Hodges, 2002. Speech and gesture multimodal control of a whole Earth 3D visualization environment. In Proceedings of the symposium on Data Visualisation 2002 (VISSYM '02), pp. 195‚Äì200

- Kopp, Gesellensetter, Kr√§mer, Wachsmuth, 2005. A conversational agent as museum guide: design and evaluation of a real-world application. In Lecture Notes in Computer Science, pp. 329‚Äì343, DOI: [10.1007/11550617_28](https//doi.org/10.1007/11550617_28)

- Tse, Shen, Greenberg, Forlines, 2006. Enabling interaction with single user applications through speech and gestures on a multi-user tabletop. In Proceedings of the working conference on Advanced visual interfaces (AVI ‚Äò06), pp. 336‚Äì343, DOI: [10.1145/1133265.1133336](https://doi.org/10.1145/1133265.1133336)

- Harada, Saponas, Landay, 2007. VoicePen: augmenting pen input with simultaneous non-linguisitic vocalization. In Proceedings of the 9th international conference on Multimodal interfaces (ICMI ‚Äò07), pp. 178‚Äì185, DOI: [10.1145/1322192.1322225](https://doi.org/10.1145/1322192.1322225)

- Sherwani, Yu, Paek, Czerwinski, Ju, Acero, 2007. Voicepedia: towards speech-based access to unstructured information.¬†In Interspeech.

- Harada, Wobbrock, Landay, 2011. Voice Games: Investigation Into the Use of Non-speech Voice Input for Making Computer Games More Accessible. In Human-Computer Interaction ‚Äì INTERACT 2011, vol 6946, DOI: [10.1007/978-3-642-23774-4_4](https://doi.org/10.1007/978-3-642-23774-4_4)

- Pfeifer Vardoulakis, Ring, Barry, Sidner, Bickmore, 2012. Designing relational agents as long term social companions for older adults. In Proceedings of the 12th international conference on Intelligent Virtual Agents (IVA‚Äô12), pp. 289‚Äì302, DOI: [10.1007/978-3-642-33197-8_30] 

- Portet, Vacher, Golanski, Meillon, 2013.¬†Design and evaluation of a smart home voice interface for the elderly: acceptability and objection aspects. In¬†Pers Ubiquit Comput¬†17,¬†pp. 127‚Äì144, DOI: [10.1007/s00779-011-0470-5]

- Sakamoto, Komatsu, Igarashi, 2013. Voice augmented manipulation: using paralinguistic information to manipulate mobile devices. In Proceedings of the 15th international conference on Human-computer interaction with mobile devices and services (MobileHCI ‚Äò13), pp. 69‚Äì78, DOI: [10.1145/2493190.2493244](https://doi.org/10.1145/2493190.2493244)

- DeVault, Artstein, Benn, Dey, Fast, Gainer, Georgila, Gratch, Hartholt, Lhommet, Lucas, Marsella, Morbini, Nazarian, Scherer, Stratou, Suri, Traum, Wood, Xu, Rizzo, Morency, 2014. SimSensei Kiosk: A Virtual Human Interviewer for Healthcare Decision Support. In Proceedings of the 2014 international conference on Autonomous agents and multi-agent systems (AAMAS ‚Äò14), pp. 1061‚Äì1068

- Braun, Broy, Pfleging, Alt, 2017. A design space for conversational in-vehicle information systems. In Proceedings of the 19th International Conference on Human-Computer Interaction with Mobile Devices and Services (MobileHCI ‚Äò17), Article 79, DOI:[10.1145/3098279.3122122](https://doi.org/10.1145/3098279.3122122)

- Lin, Hsu, Talamonti, Zhang, Oney, Mars, Tang, 2018. Adasa: A Conversational In-Vehicle Digital Assistant for Advanced Driver Assistance Features. In Proceedings of the 31st Annual ACM Symposium on User Interface Software and Technology (UIST ‚Äò18), pp. 531‚Äì542, DOI: [10.1145/3242587.3242593](https://doi.org/10.1145/3242587.3242593)

- Roider, Reisig, Gross, 2018. Just Look: The Benefits of Gaze-Activated Voice Input in the Car. In Adjunct Proceedings of the 10th International Conference on Automotive User Interfaces and Interactive Vehicular Applications (AutomotiveUI ‚Äò18), pp. 210‚Äì214, DOI: [10.1145/3239092.3265968](https://doi.org/10.1145/3239092.3265968)

- Detjen, Faltaous, Geisler, Schneegass, 2019. User-Defined Voice and Mid-Air Gesture Commands for Maneuver-based Interventions in Automated Vehicles. In Proceedings of Mensch und Computer 2019 (MuC‚Äô19), pp. 341‚Äì348, DOI: [10.1145/3340764.3340798](https://doi.org/10.1145/3340764.3340798)

- Fernandes, Abreu, Almeida, Santos, 2019. A Review of Voice User Interfaces for Interactive TV. In: Applications and Usability of Interactive TV. jAUTI 2018. Communications in Computer and Information Science, vol 1004, DOI: [10.1007/978-3-030-23862-9_9](https://doi.org/10.1007/978-3-030-23862-9_9)

- **Mayer, Laput, Harrison, 2020. Enhancing Mobile Voice Assistants with WorldGaze. In Proceedings of the 38th Annual SIGCHI Conference on Human Factors in Computing Systems (CHI ‚Äò20), DOI: [10.1145/3313831.3376479](https://doi.org/10.1145/3313831.3376479)**

- Williams, Cambre, Bicking, Wallin, Tsai, Kaye, 2020. Toward Voice-Assisted Browsers: A Preliminary Study with Firefox Voice. In Proceedings of the 2nd Conference on Conversational User Interfaces (CUI ‚Äò20), Article 49, DOI: [10.1145/3405755.3406154](https://doi.org/10.1145/3405755.3406154)

- Hermann, Pl√ºckthun, Dogang√ºn, Hesenius, 2022. User-Defined Gesture and Voice Control in Human-Drone Interaction for Police Operations. In Proceedings of the Nordic Human-Computer Interaction Conference (NordiCHI '22), DOI: [10.1145/3546155.3546661](https://doi.org/10.1145/3546155.3546661)

- Khan, Newn, Bailey, Velloso, 2022. Integrating Gaze and Speech for Enabling Implicit Interactions. In Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems (CHI '22). DOI: [10.1145/3491102.3502134](https://doi.org/10.1145/3491102.3502134) [üìÑ](gaze/2022-Khan%20-%20Integrating%20Gaze%20and%20Speech.pdf)

- Parthiban, Maes, Sellier, Sluyters, Vanderdonckt, 2022. Gestural-Vocal Coordinated Interaction on Large Displays. In Companion of the 2022 ACM SIGCHI Symposium on Engineering Interactive Computing Systems (EICS '22), pp. 26-32, DOI: [10.1145/3531706.3536457](https://doi.org/10.1145/3531706.3536457)

<br/>



## üëÅÔ∏è Gaze Interaction


### General

- **Jacob, 1990. What you look at is what you get: eye movement-based interaction techniques. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI ‚Äò90), pp. 11‚Äì18, DOI: [10.1145/97243.97246](https://doi.org/10.1145/97243.97246)** [üìÑ](gaze/1990-Jacob%20-%20What%20you%20look%20at%20is%20what%20you%20get%20eye%20movement-based%20interaction%20techniques.pdf)

- Sibert & Jacob, 2000. Evaluation of eye gaze interaction. In Proceedings of the SIGCHI conference on Human Factors in Computing Systems (CHI ‚Äò00), pp. 281‚Äì288, DOI: [10.1145/332040.332445](https://doi.org/10.1145/332040.332445) [üìÑ](gaze/2000-Siebert%20et%20al.%20-%20Evaluation%20of%20eye%20gaze%20interaction.pdf)

- Kumar, 2007. Gaze-Enhanced User Interface Design. Phd Thesis, Stanford University [üéì](gaze/2007-Kumar%20-%20Gaze-Enhanced%20User%20Interface%20Design.pdf)

- Vertegaal, 2008. A Fitts Law comparison of eye tracking and manual input in the selection of visual targets. In Proceedings of the 10th international conference on Multimodal interfaces (ICMI '08), pp. 241‚Äì248, DOI: [10.1145/1452392.1452443](https://doi.org/10.1145/1452392.1452443) [üìÑ](gaze/2008-Vertegaal%20-%20A%20Fitts%E2%80%99%20Law%20Comparison%20of%20Eye%20Tracking%20and%20Manual%20Input.pdf)

- Vrzakova & Bednarik, 2013. That's not Norma(n/l): A Detailed Analysis of Midas Touch in Gaze-based Problem-Solving. In CHI '13 Extended Abstracts on Human Factors in Computing Systems (CHI EA ‚Äò13), pp. 85‚Äì90, DOI: [10.1145/2468356.2468373](https://doi.org/10.1145/2468356.2468373) [üìÑ](gaze/2013-Vrzakova%20et%20al.%20-%20That's%20not%20norma(n-l)%20a%20detailed%20analysis%20of%20midas%20touch%20in%20gaze-based%20problem-solving.pdf)

- Feit, Williams, Toledo, Paradiso, Kulkarni, Kane, Ringel Morris, 2017. Toward Everyday Gaze Input: Accuracy and Precision of Eye Tracking and Implications for Design. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (CHI ‚Äò17), pp. 1118‚Äì1130, DOI: [10.1145/3025453.3025599](https://doi.org/10.1145/3025453.3025599) [üìÑ](gaze/2017-Feit%20et%20al.%20-%20Toward%20Everyday%20Gaze%20Input%20Accuracy%20and%20Precision%20of%20Eye%20Tracking%20and%20Implications%20for%20Design.pdf)

- Klaib, Alsrehin, Melhem, Bashtawi, Magableh, 2020. Eye Tracking Algorithms, Techniques, Tools, and Applications with an Emphasis on Machine Learning and Internet of Things Technologies (Chapter 7), DOI: [10.1016/j.eswa.2020.114037](https://doi.org/10.1016/j.eswa.2020.114037) [üìÑ](gaze/2020-K%7E1.PDF)


### Applications


- Smith & Graham, 2006. Use of eye movements for video game control. In Proceedings of the 2006 ACM SIGCHI international conference on Advances in computer entertainment technology (ACE ‚Äò06), DOI: [10.1145/1178823.1178847](https://doi.org/10.1145/1178823.1178847) 

- Tall, Alapetite, San Agustin, Skovsgaard, Hansen, Witzner Hansen, M√∏llenbach, 2009. Gaze-controlled driving. In CHI '09 Extended Abstracts on Human Factors in Computing Systems (CHI EA ‚Äò09), pp. 4387‚Äì4392, DOI: [10.1145/1520340.1520671](https://doi.org/10.1145/1520340.1520671) 

- Turner, Bulling, Gellersen, 2011. Combining gaze with manual interaction to extend physical reach. In Proceedings of the 1st international workshop on pervasive eye tracking & mobile eye-based interaction (PETMEI ‚Äò11), pp. 33‚Äì36, DOI: [10.1145/2029956.2029966](https://doi.org/10.1145/2029956.2029966) 

- Stellmach & Dachselt, 2012. Designing gaze-based user interfaces for steering in virtual environments. In Proceedings of the Symposium on Eye Tracking Research and Applications (ETRA ‚Äò12), pp. 131‚Äì138, DOI: [10.1145/2168556.216857](https://doi.org/10.1145/2168556.216857) 

- Stellmach & Dachselt, 2012. Look & touch: gaze-supported target acquisition. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI ‚Äò12), pp. 2981‚Äì2990, DOI: [10.1145/2207676.2208709](https://doi.org/10.1145/2207676.2208709)

- G√∂bel, Klamka, Siegel, Vogt, Stellmach, Dachselt, 2013. Gaze-Supported Foot Interaction in Zoomable Information Spaces. In: Extended Abstracts on Human Factors in Computing Systems, pp. 3059‚Äì3062, DOI: [10.1145/2468356.2479610](https://doi.org/10.1145/2468356.2479610) 

- Pfeuffer, Alexander, Chong, Gellersen, 2014. Gaze-touch: combining gaze with multi-touch for interaction on the same surface. In Proceedings of the 27th annual ACM symposium on User interface software and technology (UIST ‚Äò14), 509‚Äì518, DOI: [10.1145/2642918.2647397](https://doi.org/10.1145/2642918.2647397) 

- Pfeuffer, Alexander, Chong, Zhang, Gellersen. 2015, Gaze-Shifting: Direct-Indirect Input with Pen and Touch Modulated by Gaze. In Proceedings of the 28th Annual ACM Symposium on User Interface Software & Technology (UIST ‚Äò15), pp. 373‚Äì383, DOI: [10.1145/2807442.2807460](https://doi.org/10.1145/2807442.2807460)

- Hansen, Lund, Biermann, M√∏llenbach, Sztuk, San Agustin, 2016. Wrist-worn pervasive gaze interaction. In Proceedings of the Ninth Biennial ACM Symposium on Eye Tracking Research &amp; Applications (ETRA ‚Äò16), pp. 57‚Äì64, DOI: [10.1145/2857491.2857514](https://doi.org/10.1145/2857491.2857514)

- D'Angelo & Gergle, 2016. Gazed and Confused: Understanding and Designing Shared Gaze for Remote Collaboration. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems (CHI ‚Äò16), pp. 2492‚Äì2496, DOI: [10.1145/2858036.2858499](https://doi.org/10.1145/2858036.2858499)

- Pfeuffer & Gellersen, 2016. Gaze and Touch Interaction on Tablets. In Proceedings of the 29th Annual Symposium on User Interface Software and Technology (UIST ‚Äò16), pp. 301‚Äì311, DOI: [10.1145/2984511.2984514](https://doi.org/10.1145/2984511.2984514)

- D'Angelo & Begel, 2017. Improving Communication Between Pair Programmers Using Shared Gaze Awareness. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (CHI ‚Äò17), pp. 6245‚Äì6290, DOI: [10.1145/3025453.3025573](https://doi.org/10.1145/3025453.3025573)

- Khamis, Hoesl, Klimczak, Reiss, Alt, Bulling, 2017. EyeScout: Active Eye Tracking for Position and Movement Independent Gaze Interaction with Large Public Displays. In Proceedings of the 30th Annual ACM Symposium on User Interface Software and Technology (UIST ‚Äò17), pp. 155‚Äì166, DOI: [10.1145/3126594.3126630](https://doi.org/10.1145/3126594.3126630)

- Newn, Allison, Velloso, Vetere. 2018, Looks Can Be Deceiving: Using Gaze Visualisation to Predict and Mislead Opponents in Strategic Gameplay. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI ‚Äò18), DOI: [10.1145/3173574.3173835](https://doi.org/10.1145/3173574.3173835)

- Kyt√∂, Ens, Piumsomboon, Lee, Billinghurst, 2018. Pinpointing: Precise Head- and Eye-Based Target Selection for Augmented Reality. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems, Paper 81, DOI: [10.1145/3173574.3173655](https://doi.org/10.1145/3173574.3173655) 

- Khamis, Kienle, Alt, Bulling, 2018. GazeDrone: Mobile Eye-Based Interaction in Public Space Without Augmenting the User. In Proceedings of the 4th ACM Workshop on Micro Aerial Vehicle Networks, Systems, and Applications (DroNet‚Äô18), pp. 66‚Äì71, DOI: [10.1145/3213526.3213539](https://doi.org/10.1145/3213526.3213539) 

- Khamis, Alt, Bulling, 2018. The Past, Present, and Future of Gaze-Enabled Handheld Mobile Devices: Survey and Lessons Learned. In Proceedings of the 20th International Conference on Human-Computer Interaction with Mobile Devices and Services (MobileHCI ‚Äò18), Article 38, DOI: [10.1145/3229434.3229452](https://doi.org/10.1145/3229434.3229452) 

- Roider, Reisig, Gross, 2018. Just Look: The Benefits of Gaze-Activated Voice Input in the Car. In Adjunct Proceedings of the 10th International Conference on Automotive User Interfaces and Interactive Vehicular Applications (AutomotiveUI ‚Äò18), pp. 210‚Äì214, DOI: [10.1145/3239092.3265968](https://doi.org/10.1145/3239092.3265968) 

- Kim, Choi, Jeong, 2019. Watch & Do: A Smart IoT Interaction System with Object Detection and Gaze Estimation. In IEEE Trans. on Consum. Electron. 65, 2 (May 2019), 195‚Äì204, DOI: [10.1109/TCE.2019.2897758](https://doi.org/10.1109/TCE.2019.2897758) 

- K√ºtt, Lee, Hardacre, Papoutsaki, 2019. Eye-Write: Gaze Sharing for Collaborative Writing. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems (CHI ‚Äò19), Paper 497, DOI: [10.1145/3290605.3300727](https://doi.org/10.1145/3290605.3300727) 

- Newn, Singh , Allison, Madumal, Velloso, Vetere, 2019. Designing Interactions with Intention-Aware Gaze-Enabled Artificial Agents. In: Proceedings INTERACT 2019, DOI: [10.1007/978-3-030-29384-0_17](https://doi.org/10.1007/978-3-030-29384-0_17) 

- Mayer, Laput, Harrison, 2020. Enhancing Mobile Voice Assistants with WorldGaze. In Proceedings of the 38th Annual SIGCHI Conference on Human Factors in Computing Systems (CHI ‚Äò20), DOI: [10.1145/3313831.3376479](https://doi.org/10.1145/3313831.3376479) 

- Pfeuffer, Alexander, Gellersen, 2021. Multi-user Gaze-Based Interaction Techniques on Collaborative Touchscreens. In 2021 Symposium on Eye Tracking Research and Applications (ETRA '21), DOI: [10.1145/3448018.3458016](https://doi.org/10.1145/3448018.3458016) 

- Khan, Newn, Bailey, Velloso, 2022. Integrating Gaze and Speech for Enabling Implicit Interactions. In Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems (CHI '22). DOI: [10.1145/3491102.3502134](https://doi.org/10.1145/3491102.3502134) 

- Reiter, Pfeuffer, Esteves, Mittermeier, Alt, 2022. Look & Turn: One-handed and Expressive Menu Interaction by Gaze and Arm Turns in VR. In 2022 Symposium on Eye Tracking Research and Applications (ETRA '22), DOI: [10.1145/3517031.3529233](https://doi.org/10.1145/3517031.3529233)

- Lystb√¶k, Rosenberg, Pfeuffer, Gr√∏nb√¶k, Gellersen, 2022. Gaze-Hand Alignment: Combining Eye Gaze and Mid-Air Pointing for Interacting with Menus in Augmented Reality. In Proceedings of the ACM on Human-Computer Interaction, DOI: [10.1145/3530886](https://doi.org/10.1145/3530886)

- Cui, Liu, Li, Wang, Zhao, Rashidian, Baik, Ramakrishnan, Wang, Bi, 2023. GlanceWriter: Writing Text by Glancing Over Letters with Gaze. In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems (CHI '23), DOI: [10.1145/3544548.3581269](https://doi.org/10.1145/3544548.3581269)

- Namnakani, Abdrabou, Grizou, Esteves, Khamis, 2023. Comparing Dwell Time, Pursuits and Gaze Gestures for Gaze Interaction on Handheld Mobile Devices. In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems (CHI '23), DOI: [10.1145/3544548.3580871](https://doi.org/10.1145/3544548.3580871)

- Namnakani, Sinrattanavong, Abdrabou, Bulling, Alt, Khamis, 2023. GazeCast: Using Mobile Devices to Allow Gaze-based Interaction on Public Displays. In Proceedings of the 2023 Symposium on Eye Tracking Research and Application (ETRA '23), DOI: [10.1145/3588015.3589663](https://doi.org/10.1145/3588015.3589663)

- Cai, Hong, Wang, Lu, 2025. GazeSwipe: Enhancing Mobile Touchscreen Reachability through Seamless Gaze and Finger-Swipe Integration. In Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems (CHI '25), DOI: [10.1145/3706598.3713739](https://doi.org/10.1145/3706598.3713739)


<br/>


## üìè Proxemic & Spatially-Aware Interaction


### General


- Hall, 1966. The Hidden Dimension. Anchor Books [üìñ](proxemic/1966-Hall%20The%20Hidden%20Dimension.pdf)

- Ballendat, Marquardt, Greenberg, 2010. Proxemic interaction: Designing for a Proximity and Orientation-Aware Environment. In¬†ACM International Conference on Interactive Tabletops and Surfaces¬†(ITS '10), pp.121-130, DOI: [10.1145/1936652.1936676](https://doi.org/10.1145/1936652.1936676) [üìÑ](proxemic/2010-Ballendat%20et%20al.%20-%20Proxemic%20interaction%20designing%20for%20a%20proximity%20and%20orientation-aware%20environment.pdf)

- **Greenberg, Marquardt, Ballendat, Diaz-Marino, Wang, 2011. Proxemic Interactions: The New Ubicomp?.¬†In Interactions¬†18, 1 (January 2011), pp. 42-50, DOI: [10.1145/1897239.1897250](https://doi.org/10.1145/1897239.1897250)** [üìÑ](proxemic/2011-Greenberg%20et%20al.%20-%20Proxemic%20interactions%20the%20new%20ubicomp.pdf)

- Marquardt, Diaz-Marino, Boring, Greenberg, 2011. The Proximity Toolkit: Prototyping Proxemic Interactions in Ubiquitous Computing Ecologies. In¬†Proceedings of the 24th Annual ACM Symposium on User Interface Software and Technology¬†(UIST '11), DOI: [10.1145/2047196.2047238](https://doi.org/10.1145/2047196.2047238) [üìÑ](proxemic/2011-Marquardt%20et%20al.%20-%20The%20proximity%20toolkit%20prototyping%20proxemic%20interactions%20in%20ubiquitous%20computing%20ecologies.pdf)

- Marquardt, Hinckley, Greenberg, 2012. Cross-device Interaction via Micro-Mobility and F-Formations. In¬†Proceedings of the 25th Annual ACM Symposium on User Interface Software and Technology¬†(UIST '12), pp. 13-22, DOI: [10.1145/2380116.2380121](https://doi.org/10.1145/2380116.2380121) [üìÑ](proxemic/2012-Marquardt%20et%20al.%20-%20Cross-device%20interaction%20via%20micro-mobility%20and%20f-formations.pdf)

- Marquardt, 2013. Proxemic Interactions in Ubiquitous Computing Ecologies. PhD Thesis, University of Calgary [üéì](proxemic/2013-Marquardt%20-%20Proxemic%20Interactions%20in%20Ubiquitous%20Computing%20Ecologies.pdf)

- Greenberg, Boring, Vermeulen, Dostal, 2014. Dark Patterns in Proxemic Interactions: A Critical Perspective. In Proceedings of the 2014 Conference on Designing Interactive Systems (DIS ‚Äò14), pp. 523‚Äì532, DOI: [10.1145/2598510.2598541](https://doi.org/10.1145/2598510.2598541) [üìÑ](proxemic/2014-Greenberg%20et%20al.%20-%20Dark%20Patterns%20in%20Proxemic%20Interaction.pdf)


### Applications


- Brumitt, Meyers, Krumm, Kern, Shafer, 2000. EasyLiving: Technologies for Intelligent Environments. In Proceedings of the 2nd International Symposium on Handheld and Ubiquitous Computing (HUC ‚Äò00), pp. 12‚Äì29, DOI: [10.1007/3-540-39959-3_2](https://doi.org/10.1007/3-540-39959-3_2) [üìÑ](proxemic/2000-Brumitt%20et%20al.%20-%20EasyLiving%20Technologies%20for%20Intelligent%20Environments.pdf)

- Vogel & Balakrishnan, 2004. Interactive Public Ambient Displays: Transitioning from Implicit to Explicit, Public to Personal, Interaction with Multiple Users. In Proceedings of the 17th Annual ACM Symposium on User Interface Software and Technology (UIST '04), pp. 137‚Äì146, DOI: [10.1145/1029632.1029656](https://doi.org/10.1145/1029632.1029656) [üìÑ](proxemic/2004-V%7E1.PDF)

- Ju, Lee, Klemmer, 2008. Range: Exploring Implicit Interaction Through Electronic Whiteboard Design. In Proceedings of the 2008 ACM Conference on Computer Supported Cooperative Work (CSCW ‚Äò08), pp. 17‚Äì26, DOI: [10.1145/1460563.1460569](https://doi.org/10.1145/1460563.1460569) [üìÑ](proxemic/2008-Ju%20et%20al.%20-%20Range%20exploring%20implicit%20interaction%20through.pdf)

- Annett, Grossman, Wigdor, Fitzmaurice, 2011. Medusa: A Proximity-Aware Multi-Touch Tabletop. In Proceedings of the 24th Annual ACM Symposium on User Interface Software and Technology (UIST ‚Äò11), pp. 337‚Äì346, DOI: [10.1145/2047196.2047240](https://doi.org/10.1145/2047196.2047240) [üìÑ](proxemic/2011-Annett%20et%20al.%20-%20Medusa%20A%20Proximity-Aware%20Multi-touch%20Tabletop.pdf)

- Chen, Boring, Carpendale, Tang, Greenberg, 2012. SPALENDAR: Visualizing a Group‚Äôs Calendar Events over a Geographic Space on a Public Display. In Proceedings of the 11th International Working Conference on Advanced Visual Interfaces (AVI ‚Äô12), DOI: [10.11575/PRISM/30760](https://dx.doi.org/10.11575/PRISM/30760) [üìÑ](proxemic/2012-Chen%20-%20SPALENDAR%20Visualizing%20a%20Group's%20Calendar%20Events%20over%20a%20Geographic%20Space%20on%20a%20Public%20Display.pdf)

- Wang, Boring, Greenberg, 2012. Proxemic Peddler: A Public Advertising Display That Captures and Preserves the Attention of a Passerby. In Proceedings of the 2012 International Symposium on Pervasive Displays (PerDis ‚Äò12), Article 3, DOI: [10.1145/2307798.2307801](https://doi.org/10.1145/2307798.2307801) [üìÑ](proxemic/2012-Wang%20-%20Proxemic%20Peddler%20A%20Public%20Advertising%20Display%20that%20Captures%20and%20Preserves%20the%20Attention%20of%20a%20Passerby.pdf)

- Aseniero, Tang, Carpendale, Greenberg, 2013. Showing Real-time Recommendations to Explore the Stages of Reflection and Action. Technical Report #2013-1040-07, Department of Computer Science, University of Calgary [üìÑ](proxemic/2013-Aseneiro%20-%20Showing%20Real-time%20Recommendations.pdf)

- Streitz, Prante, R√∂cker, Van Alphen, Magerkurth, Stenzel, Plewe, 2013. Ambient Displays and Mobile Devices for the Creation of Social Architectural Spaces. In Public and Situated Displays - Social and Interactional Aspects of Shared Display Technologies, pp. 387-409, DOI: [10.1007/978-94-017-2813-3_16](https://doi.org/10.1007/978-94-017-2813-3_16) [üìÑ](proxemic/2013-Streitz%20et%20al.%20-%20Ambient%20Displays%20and%20Mobile%20Devices%20for%20the%20Creation%20of%20Social%20Architectural%20Spaces.pdf)

- Mueller, Stellmach, Greenberg, Dippon, Boll, Garner, Khot, Naseem, Altimira, 2014. Proxemics Play: Understanding Proxemics for Designing Digital Play Experiences. In Proceedings of the 2014 Conference on Designing Interactive Systems (DIS ‚Äò14), pp. 533‚Äì542, DOI: [10.1145/2598510.2598532](https://doi.org/10.1145/2598510.2598532) [üìÑ](proxemic/2014-Mueller%20-%20Proxemics%20play%20understanding%20proxemics%20for%20designing%20digital%20play%20experiences.pdf)

- R√§dle, Jetter, Marquardt, Reiterer, Rogers, 2014. HuddleLamp: Spatially-Aware Mobile Displays for Ad-hoc Around-the-Table Collaboration. In Proceedings of the 9th ACM International Conference on Interactive Tabletops and Surfaces (ITS '14), pp. 45-54, DOI: [10.1145/2669485.2669500](https://doi.org/10.1145/2669485.2669500) [üìÑ](proxemic/2014-R%C3%A4dle%20et%20al.%20-%20HuddleLamp%20Spatially-Aware%20Mobile%20Displays%20for%20Ad-hoc%20Around-the-Table%20Collaboration.pdf)

- Kister, Reipschl√§ger, Matulic, Dachselt, 2015. BodyLenses: Embodied Magic Lenses and Personal Territories for Wall Displays. In Proceedings of the 2015 International Conference on Interactive Tabletops & Surfaces (ITS ‚Äò15), pp. 117‚Äì126, DOI: [10.1145/2817721.2817726](https://doi.org/10.1145/2817721.2817726) [üìÑ](proxemic/2015-Kister%20et%20al.%20-%20BodyLenses%20%E2%80%93%20Embodied%20Magic%20Lenses%20and%20Personal%20Territories%20for%20Wall%20Displays..pdf)

- Ledo, Greenberg, Marquardt, Boring, 2015. Proxemic-Aware Controls: Designing Remote Controls for Ubiquitous Computing Ecologies. In Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services (MobileHCI '15), pp. 187‚Äì198, DOI: [10.1145/2785830.2785871](https://doi.org/10.1145/2785830.2785871) [üìÑ](proxemic/2015-Ledo%20et%20al.%20-%20Proxemic-Aware%20Controls%20Designing%20Remote%20Controls%20for%20Ubiquitous%20Computing%20Ecologies.pdf)

- Vermeulen, Luyten, Coninx, Marquardt, Bird, 2015. Proxemic Flow: Dynamic Peripheral Floor Visualizations for Revealing and Mediating Large Surface Interactions. In Proceedings of the 15th IFIP TC.13 International Conference on Human-Computer Interaction (INTERACT 2015). Lecture Notes in Computer Science, vol 9299, DOI: [10.1007/978-3-319-22723-8_22](https://doi.org/10.1007/978-3-319-22723-8_22) [üìÑ](proxemic/2015-V%7E1.PDF)

- Houben, Vermeulen, Klokmose, Sch√∂ning, Marquardt, and Reiterer. 2016. Cross-Surface: Challenges and Opportunities of Spatial and Proxemic Interaction. In Proceedings of the 2016 ACM International Conference on Interactive Surfaces and Spaces (ISS '16),  pp. 509‚Äì51, DOI: [10.1145/2992154.2996360](https://doi.org/10.1145/2992154.2996360) [üìÑ](proxemic/2016-Houben%20et%20al.%20-%20Cross-Surface%20Challenges%20and%20Opportunities%20of%20Spatial%20and%20Proxemic%20Interaction.pdf)

- Porcheron, Lucero, Quigley, Marquardt, Clawson, O'Hara, 2016. Proxemic Mobile Collocated Interactions. In Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems (CHI EA '16), pp. 3309‚Äì3316, DOI: [10.1145/2851581.2856471](https://doi.org/10.1145/2851581.2856471) [üìÑ](proxemic/2016-Porcheron%20et%20al.%20-%20Proxemic%20Mobile%20Collocated%20Interactions.pdf)

- Tong, Serna, Pageaud, George, Tabard, 2016. It's Not how you Stand, it's how you Move: F-Formations and Collaboration Dynamics in a Mobile Learning Game. In Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services (MobileHCI ‚Äò16), pp. 318‚Äì329, DOI: [10.1145/2935334.2935343](https://doi.org/10.1145/2935334.2935343) [üìÑ](proxemic/2016-T%7E1.PDF)

- Marquardt, Riche, Holz, Romat, Pahud, Brudy, Ledo, Park, Nicholas, Seyed, Ofek, Lee, Buxton, Hinckley, 2021. AirConstellations: In-Air Device Formations for Cross-Device Interaction via Multiple Spatially-Aware Armatures. In Proceedings of the 34th Annual ACM Symposium on User Interface Software and Technology (UIST '21), pp. 1252-1268, DOI: [10.1145/3472749.3474820](https://doi.org/10.1145/3472749.3474820) [üìÑ](proxemic/2021-Marquardt%20et%20al.%20-%20AirConstellations.pdf)
