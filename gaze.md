## üëÅÔ∏è Gaze Interaction


### General

- Jacob, 1990. What you look at is what you get: eye movement-based interaction techniques. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI ‚Äò90), pp. 11‚Äì18, DOI: [10.1145/97243.97246](https://doi.org/10.1145/97243.97246)

- Sibert & Jacob, 2000. Evaluation of eye gaze interaction. In Proceedings of the SIGCHI conference on Human Factors in Computing Systems (CHI ‚Äò00), pp. 281‚Äì288, DOI: [10.1145/332040.332445](https://doi.org/10.1145/332040.332445)

- Kumar, 2007. Gaze-Enhanced User Interface Design. Phd Thesis, Stanford University 

- Vertegaal, 2008. A Fitts Law comparison of eye tracking and manual input in the selection of visual targets. In Proceedings of the 10th international conference on Multimodal interfaces (ICMI '08), pp. 241‚Äì248, DOI: [10.1145/1452392.1452443](https://doi.org/10.1145/1452392.1452443) 

- Vrzakova & Bednarik, 2013. That's not Norma(n/l): A Detailed Analysis of Midas Touch in Gaze-based Problem-Solving. In CHI '13 Extended Abstracts on Human Factors in Computing Systems (CHI EA ‚Äò13), pp. 85‚Äì90, DOI: [10.1145/2468356.2468373](https://doi.org/10.1145/2468356.2468373)

- Majaranta & Bulling. 2014. Eye Tracking and Eye-Based Human‚ÄìComputer Interaction. In Advances in Physiological Computing, Chapter 3, pp. 39‚Äì65, DOI: [10.1007/978-1-4471-6392-3_3](http://dx.doi.org/10.1007/978-1-4471-6392-3_3)

- Feit, Williams, Toledo, Paradiso, Kulkarni, Kane, Ringel Morris, 2017. Toward Everyday Gaze Input: Accuracy and Precision of Eye Tracking and Implications for Design. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (CHI ‚Äò17), pp. 1118‚Äì1130, DOI: [10.1145/3025453.3025599](https://doi.org/10.1145/3025453.3025599) 

- Klaib, Alsrehin, Melhem, Bashtawi, Magableh, 2020. Eye Tracking Algorithms, Techniques, Tools, and Applications with an Emphasis on Machine Learning and Internet of Things Technologies (Chapter 7), DOI: [10.1016/j.eswa.2020.114037](https://doi.org/10.1016/j.eswa.2020.114037) 


### Applications


- Smith & Graham, 2006. Use of eye movements for video game control. In Proceedings of the 2006 ACM SIGCHI international conference on Advances in computer entertainment technology (ACE ‚Äò06), DOI: [10.1145/1178823.1178847](https://doi.org/10.1145/1178823.1178847) 

- Tall, Alapetite, San Agustin, Skovsgaard, Hansen, Witzner Hansen, M√∏llenbach, 2009. Gaze-controlled driving. In CHI '09 Extended Abstracts on Human Factors in Computing Systems (CHI EA ‚Äò09), pp. 4387‚Äì4392, DOI: [10.1145/1520340.1520671](https://doi.org/10.1145/1520340.1520671) 

- Turner, Bulling, Gellersen, 2011. Combining gaze with manual interaction to extend physical reach. In Proceedings of the 1st international workshop on pervasive eye tracking & mobile eye-based interaction (PETMEI ‚Äò11), pp. 33‚Äì36, DOI: [10.1145/2029956.2029966](https://doi.org/10.1145/2029956.2029966) 

- Stellmach & Dachselt, 2012. Designing gaze-based user interfaces for steering in virtual environments. In Proceedings of the Symposium on Eye Tracking Research and Applications (ETRA ‚Äò12), pp. 131‚Äì138, DOI: [10.1145/2168556.216857](https://doi.org/10.1145/2168556.216857) 

- Stellmach & Dachselt, 2012. Look & touch: gaze-supported target acquisition. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI ‚Äò12), pp. 2981‚Äì2990, DOI: [10.1145/2207676.2208709](https://doi.org/10.1145/2207676.2208709)

- G√∂bel, Klamka, Siegel, Vogt, Stellmach, Dachselt, 2013. Gaze-Supported Foot Interaction in Zoomable Information Spaces. In: Extended Abstracts on Human Factors in Computing Systems, pp. 3059‚Äì3062, DOI: [10.1145/2468356.2479610](https://doi.org/10.1145/2468356.2479610) 

- Pfeuffer, Alexander, Chong, Gellersen, 2014. Gaze-touch: combining gaze with multi-touch for interaction on the same surface. In Proceedings of the 27th annual ACM symposium on User interface software and technology (UIST ‚Äò14), 509‚Äì518, DOI: [10.1145/2642918.2647397](https://doi.org/10.1145/2642918.2647397) 

- Pfeuffer, Alexander, Chong, Zhang, Gellersen. 2015, Gaze-Shifting: Direct-Indirect Input with Pen and Touch Modulated by Gaze. In Proceedings of the 28th Annual ACM Symposium on User Interface Software & Technology (UIST ‚Äò15), pp. 373‚Äì383, DOI: [10.1145/2807442.2807460](https://doi.org/10.1145/2807442.2807460)

- Hansen, Lund, Biermann, M√∏llenbach, Sztuk, San Agustin, 2016. Wrist-worn pervasive gaze interaction. In Proceedings of the Ninth Biennial ACM Symposium on Eye Tracking Research &amp; Applications (ETRA ‚Äò16), pp. 57‚Äì64, DOI: [10.1145/2857491.2857514](https://doi.org/10.1145/2857491.2857514)

- D'Angelo & Gergle, 2016. Gazed and Confused: Understanding and Designing Shared Gaze for Remote Collaboration. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems (CHI ‚Äò16), pp. 2492‚Äì2496, DOI: [10.1145/2858036.2858499](https://doi.org/10.1145/2858036.2858499)

- Pfeuffer & Gellersen, 2016. Gaze and Touch Interaction on Tablets. In Proceedings of the 29th Annual Symposium on User Interface Software and Technology (UIST ‚Äò16), pp. 301‚Äì311, DOI: [10.1145/2984511.2984514](https://doi.org/10.1145/2984511.2984514)

- **D'Angelo & Begel, 2017. Improving Communication Between Pair Programmers Using Shared Gaze Awareness. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (CHI ‚Äò17), pp. 6245‚Äì6290, DOI: [10.1145/3025453.3025573](https://doi.org/10.1145/3025453.3025573)**

- Khamis, Hoesl, Klimczak, Reiss, Alt, Bulling, 2017. EyeScout: Active Eye Tracking for Position and Movement Independent Gaze Interaction with Large Public Displays. In Proceedings of the 30th Annual ACM Symposium on User Interface Software and Technology (UIST ‚Äò17), pp. 155‚Äì166, DOI: [10.1145/3126594.3126630](https://doi.org/10.1145/3126594.3126630)

- Newn, Allison, Velloso, Vetere. 2018, Looks Can Be Deceiving: Using Gaze Visualisation to Predict and Mislead Opponents in Strategic Gameplay. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI ‚Äò18), DOI: [10.1145/3173574.3173835](https://doi.org/10.1145/3173574.3173835)

- Kyt√∂, Ens, Piumsomboon, Lee, Billinghurst, 2018. Pinpointing: Precise Head- and Eye-Based Target Selection for Augmented Reality. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems, Paper 81, DOI: [10.1145/3173574.3173655](https://doi.org/10.1145/3173574.3173655) 

- Khamis, Kienle, Alt, Bulling, 2018. GazeDrone: Mobile Eye-Based Interaction in Public Space Without Augmenting the User. In Proceedings of the 4th ACM Workshop on Micro Aerial Vehicle Networks, Systems, and Applications (DroNet‚Äô18), pp. 66‚Äì71, DOI: [10.1145/3213526.3213539](https://doi.org/10.1145/3213526.3213539) 

- Khamis, Alt, Bulling, 2018. The Past, Present, and Future of Gaze-Enabled Handheld Mobile Devices: Survey and Lessons Learned. In Proceedings of the 20th International Conference on Human-Computer Interaction with Mobile Devices and Services (MobileHCI ‚Äò18), Article 38, DOI: [10.1145/3229434.3229452](https://doi.org/10.1145/3229434.3229452) 

- Roider, Reisig, Gross, 2018. Just Look: The Benefits of Gaze-Activated Voice Input in the Car. In Adjunct Proceedings of the 10th International Conference on Automotive User Interfaces and Interactive Vehicular Applications (AutomotiveUI ‚Äò18), pp. 210‚Äì214, DOI: [10.1145/3239092.3265968](https://doi.org/10.1145/3239092.3265968) 

- Kim, Choi, Jeong, 2019. Watch & Do: A Smart IoT Interaction System with Object Detection and Gaze Estimation. In IEEE Trans. on Consum. Electron. 65, 2 (May 2019), 195‚Äì204, DOI: [10.1109/TCE.2019.2897758](https://doi.org/10.1109/TCE.2019.2897758) 

- K√ºtt, Lee, Hardacre, Papoutsaki, 2019. Eye-Write: Gaze Sharing for Collaborative Writing. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems (CHI ‚Äò19), Paper 497, DOI: [10.1145/3290605.3300727](https://doi.org/10.1145/3290605.3300727)

- Zhang, Hansen, Minakata, Alapetite, Wang, 2019. Eye-Gaze-Controlled Telepresence Robots for People with Motor Disabilities. In 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI '19). DOI: [10.1109/HRI.2019.8673093](https://doi.org/10.1109/HRI.2019.8673093)

- K√ºtt, Lee, Hardacre, Papoutsaki. 2019. Eye-Write: Gaze Sharing for Collaborative Writing. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems (CHI '19), Paper 497. DOI: [10.1145/3290605.3300727](https://doi.org/10.1145/3290605.3300727)

- Newn, Singh , Allison, Madumal, Velloso, Vetere, 2019. Designing Interactions with Intention-Aware Gaze-Enabled Artificial Agents. In: Proceedings INTERACT 2019, DOI: [10.1007/978-3-030-29384-0_17](https://doi.org/10.1007/978-3-030-29384-0_17) 

- Mayer, Laput, Harrison, 2020. Enhancing Mobile Voice Assistants with WorldGaze. In Proceedings of the 38th Annual SIGCHI Conference on Human Factors in Computing Systems (CHI ‚Äò20), DOI: [10.1145/3313831.3376479](https://doi.org/10.1145/3313831.3376479) 

- Pfeuffer, Alexander, Gellersen, 2021. Multi-user Gaze-Based Interaction Techniques on Collaborative Touchscreens. In 2021 Symposium on Eye Tracking Research and Applications (ETRA '21), DOI: [10.1145/3448018.3458016](https://doi.org/10.1145/3448018.3458016)

- Yu, Lu, Shi, Liang, Dingler, Velloso, Goncalves. 2021. Gaze-Supported 3D Object Manipulation in Virtual Reality. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems (CHI '21), Article 734. DOI: [10.1145/3411764.3445343](https://doi.org/10.1145/3411764.3445343)

- Khan, Newn, Bailey, Velloso, 2022. Integrating Gaze and Speech for Enabling Implicit Interactions. In Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems (CHI '22). DOI: [10.1145/3491102.3502134](https://doi.org/10.1145/3491102.3502134) 

- Reiter, Pfeuffer, Esteves, Mittermeier, Alt, 2022. Look & Turn: One-handed and Expressive Menu Interaction by Gaze and Arm Turns in VR. In 2022 Symposium on Eye Tracking Research and Applications (ETRA '22), DOI: [10.1145/3517031.3529233](https://doi.org/10.1145/3517031.3529233)

- Lystb√¶k, Rosenberg, Pfeuffer, Gr√∏nb√¶k, Gellersen, 2022. Gaze-Hand Alignment: Combining Eye Gaze and Mid-Air Pointing for Interacting with Menus in Augmented Reality. In Proceedings of the ACM on Human-Computer Interaction, DOI: [10.1145/3530886](https://doi.org/10.1145/3530886)

- Kim, Ham, Ahn, Lee. 2022. Lattice Menu: A Low-Error Gaze-Based Marking Menu Utilizing Target-Assisted Gaze Gestures on a Lattice of Visual Anchors. In Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems (CHI '22), Article 277. DOI: [10.1145/3491102.3501977](https://doi.org/10.1145/3491102.3501977)

- Cui, Liu, Li, Wang, Zhao, Rashidian, Baik, Ramakrishnan, Wang, Bi, 2023. GlanceWriter: Writing Text by Glancing Over Letters with Gaze. In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems (CHI '23), DOI: [10.1145/3544548.3581269](https://doi.org/10.1145/3544548.3581269)

- **Namnakani, Abdrabou, Grizou, Esteves, Khamis, 2023. Comparing Dwell Time, Pursuits and Gaze Gestures for Gaze Interaction on Handheld Mobile Devices. In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems (CHI '23), DOI: [10.1145/3544548.3580871](https://doi.org/10.1145/3544548.3580871)**

- Namnakani, Sinrattanavong, Abdrabou, Bulling, Alt, Khamis, 2023. GazeCast: Using Mobile Devices to Allow Gaze-based Interaction on Public Displays. In Proceedings of the 2023 Symposium on Eye Tracking Research and Application (ETRA '23), DOI: [10.1145/3588015.3589663](https://doi.org/10.1145/3588015.3589663)

- Colley, Wanner, R√§dler, R√∂tzer, Frommel, Hirzle, Jansen, Rukzio, 2024. Efects of a Gaze-Based 2D Platform Game on User Enjoyment, Perceived Competence, and Digital Eye Strain. In Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems (CHI '24), 
Article No.: 369, [10.1145/3613904.3641909](https://doi.org/10.1145/3613904.3641909)

- Wang, Potter, Ho, Killough, Zeng, Mondal, Zhao. 2024. GazePrompt: Enhancing Low Vision People's Reading Experience with Gaze-Aware Augmentations. In Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems (CHI '24), Article 894. DOI: [10.1145/3613904.3642878](https://doi.org/10.1145/3613904.3642878)

- Pfeuffer, Gellersen and Gonzalez-Franco, 2024. Design Principles and Challenges for Gaze + Pinch Interaction in XR. In IEEE Computer Graphics and Applications, vol. 44, no. 3, pp. 74-81. DOI: [10.1109/MCG.2024.3382961](https://doi.org/10.1109/MCG.2024.3382961)

- Cai, Hong, Wang, Lu, 2025. GazeSwipe: Enhancing Mobile Touchscreen Reachability through Seamless Gaze and Finger-Swipe Integration. In Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems (CHI '25), DOI: [10.1145/3706598.3713739](https://doi.org/10.1145/3706598.3713739)



<br/>

